[{"content":"這個專案會使用 Node.js 和 TypeScript 來建構 REST API 後端，使用 JWT 來實作身分認證與授權。\n此專案會遵循我慣用的 OOP 架構 et860525/express-project-architecture，有鑑於上一次專案的經驗，由於這些都只是小專案，我不會把所有東西都全部都包在 class 裡面\n建構此專案會用到的重要套件：\nPackage Usage Express Web 應用框架 TypeScript 開發工具 Mongoose 訪問資料庫 Docker 應用容器化 MongoDB 儲存使用者的資料庫 Redis 儲存使用者緩存的 session 資料庫 JsonWebToken 產生 JWTs Bcryptjs 密碼加密 Zod 驗證使用者的輸入 Typegoose 使用 TypeScript 優化 Mongoose 模型 Dotenv 讀取環境變數 Cors 允許資料能在前端與後端之間分享 lodash 對 JavaScript 的功能擴充 ts-node-dev 當檔案變更時自動重啟 JWT 驗證流程 使用者需要提供瀏覽器帳號密碼來做登入。前端會發送帶有使用者憑證的請求到後端，當後端驗證成功後，會傳送使用者相關的 cookies 回到前端。\n使用者註冊的流程：\n使用者登入的流程：\nAPI 路由設置 HTTP Method Route Description GET /api/users 回傳所有使用者的資訊 GET /api/users/me 回傳已登入者的資訊 POST /api/auth/register 註冊新用戶 POST /api/auth/login 登入 初始化專案 建立資料夾並初始化： mkdir jwt-auth-node cd jwt-auth-node pnpm init 安裝套件 安裝相關套件： pnpm install @typegoose/typegoose bcryptjs cookie-parser dotenv express jsonwebtoken lodash mongoose redis ts-node-dev zod cors 安裝開發用套件： pnpm install -D morgan typescript 安裝 Type Definition 檔案： pnpm install -D @types/bcryptjs @types/cookie-parser @types/express @types/jsonwebtoken @types/lodash @types/morgan @types/node @types/cors TypeScript 相關設定 產生 tsconfig.json 檔案： tsc --init tsconfig.json： { \u0026#34;compilerOptions\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;es2017\u0026#34;, \u0026#34;experimentalDecorators\u0026#34;: true, \u0026#34;emitDecoratorMetadata\u0026#34;: true, \u0026#34;module\u0026#34;: \u0026#34;commonjs\u0026#34;, \u0026#34;rootDir\u0026#34;: \u0026#34;./src\u0026#34;, \u0026#34;outDir\u0026#34;: \u0026#34;./dist\u0026#34;, \u0026#34;esModuleInterop\u0026#34;: true, \u0026#34;forceConsistentCasingInFileNames\u0026#34;: true, \u0026#34;strict\u0026#34;: true, \u0026#34;skipLibCheck\u0026#34;: true } } 在 How to Start using typegoose 有說明，以下兩個設定一定要開啟：\nexperimentalDecorators: true emitDecoratorMetadata: true 簡單的 Express Server 建立 ./.env 檔案： PORT=3000 ./src/app.ts： import dotenv from \u0026#39;dotenv\u0026#39;; import express, { Request, Response } from \u0026#39;express\u0026#39;; dotenv.config(); const env = process.env.NODE_ENV; const port = process.env.PORT; const app = express(); app.get(\u0026#39;/\u0026#39;, (req: Request, res: Response) =\u0026gt; { res.send(\u0026#39;JWT + Express + TypeScript Server\u0026#39;); }); app.listen(port, () =\u0026gt; { console.log( `[server]: Server is running at http://localhost:${port} in ${env}` ); ; 在 ./package.json 裡寫一個啟動腳本： \u0026#34;scripts\u0026#34;: { \u0026#34;dev\u0026#34;: \u0026#34;NODE_ENV=development ts-node-dev --respawn src/app.ts\u0026#34; } 啟動伺服器： pnpm dev 並訪問 http://localhost:3000 就可以看到成功畫面。\n使用 Docker Compose 設定資料庫 在專案目錄下新增一個檔案 ./docker-compose.yaml： services: mongo: image: mongo:4.4.19-focal container_name: mongo environment: MONGO_INITDB_ROOT_USERNAME: ${MONGODB_USERNAME} MONGO_INITDB_ROOT_PASSWORD: ${MONGODB_PASSWORD} MONGO_INITDB_DATABASE: ${MONGODB_DATABASE} env_file: - ./.env ports: - \u0026#39;6017:27017\u0026#39; volumes: - mongo:/data/db - ./init-mongo.sh:/docker-entrypoint-initdb.d/init-mongo.sh:ro redis: image: redis:latest container_name: redis ports: - \u0026#39;6379:6379\u0026#39; volumes: - redis:/data volumes: mongo: redis: docker-compose.yaml 檔案會使用專案下 .env 裡的設定，所以要新增所需要的相關設定：\n.env PORT=3000 MONGODB_USERNAME=jwtweb MONGODB_PASSWORD=pwd123 MONGODB_DATABASE=jwtAuth 當 MongoDB 建立後，它並不會自動建立 database。這就是 ./init-mongo.sh:/docker-entrypoint-initdb.d/init-mongo.sh:ro 的功用，寫一個初始化資料庫的檔案並掛載到容器裡。\n在專案目錄下新增一個檔案 ./init-mongo.sh：\nmongo \u0026lt;\u0026lt; EOF db = db.getSiblingDB(\u0026#39;jwtAuth\u0026#39;) db.createUser({ user: \u0026#39;${MONGODB_USERNAME}\u0026#39;, pwd: \u0026#39;${MONGODB_PASSWORD}\u0026#39;, roles: [ { role: \u0026#39;readWrite\u0026#39;, db: \u0026#39;${MONGODB_DATABASE}\u0026#39;, }, ], }); EOF 完成後使用下面指令來運行：\ndocker compose up -d 如果要停止的話可以使用：\ndocker compose down # or docker compose down -v # 停止並刪除 volume 連接到 MongoDB ./src/database/connectMongo import mongoose from \u0026#39;mongoose\u0026#39;; const db_user = process.env.MONGODB_USERNAME; const db_pwd = process.env.MONGODB_PASSWORD; const db_name = process.env.MONGODB_DATABASE; mongoose.set(\u0026#39;strictQuery\u0026#39;, false); const url = `mongodb://${db_user}:${db_pwd}@localhost:6017/${db_name}`; const connectDB = async () =\u0026gt; { try { await mongoose.connect(url); console.log(\u0026#39;Database connected...\u0026#39;); } catch (error: any) { console.log(error.message); setTimeout(connectDB, 5000); } }; export default connectDB; 讓 app.ts 連接： import connectDB from \u0026#39;./database/connectMongo\u0026#39;; //... app.listen(port, () =\u0026gt; { console.log( `[server]: Server is running at http://localhost:${port} in ${env}` ); connectDB(); }); 連接到 Redis ./src/database/connectRedis import { createClient } from \u0026#39;redis\u0026#39;; const redisUrl = \u0026#39;redis://localhost:6379\u0026#39;; const redisClient = createClient({ url: redisUrl, }); const connectRedis = async () =\u0026gt; { try { await redisClient.connect(); console.log(\u0026#39;Redis client connect...\u0026#39;); } catch (err: any) { console.log(err.message); setTimeout(connectRedis, 5000); } }; connectRedis(); redisClient.on(\u0026#39;error\u0026#39;, (err) =\u0026gt; console.log(err)); export default redisClient; 因為 Redis 只會儲存 session 狀態，所以目前還不需要套用在任何地方。\n可以到我的 et860525/jwt-auth-node 來查看程式碼\n結語 自從上一次發文後馬上就確診了，所以新的專案就停了一陣子。這次的專案是結合以前所學過的東西，來實作一個簡單的 JWT (JSON Web Tokens) RESTful API。\n下一個章節會從建立資料庫的 model 開始。\n","permalink":"https://et860525.github.io/posts/jwt-authentication-init/","summary":"\u003cp\u003e這個專案會使用 Node.js 和 TypeScript 來建構 REST API 後端，使用 \u003ca href=\"https://jwt.io/\"\u003eJWT\u003c/a\u003e 來實作身分認證與授權。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e此專案會遵循我慣用的 OOP 架構  \u003ca href=\"https://github.com/et860525/express-project-architecture\"\u003eet860525/express-project-architecture\u003c/a\u003e，有鑑於上一次專案的經驗，由於這些都只是小專案，我不會把所有東西都全部都包在 class 裡面\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e建構此專案會用到的重要套件：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003ePackage\u003c/th\u003e\n\u003cth\u003eUsage\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://expressjs.com/\"\u003eExpress\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eWeb 應用框架\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://www.typescriptlang.org/\"\u003eTypeScript\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e開發工具\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://mongoosejs.com/\"\u003eMongoose\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e訪問資料庫\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://www.docker.com/\"\u003eDocker\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e應用容器化\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://www.mongodb.com/\"\u003eMongoDB\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e儲存使用者的資料庫\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://www.npmjs.com/package/redis\"\u003eRedis\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e儲存使用者緩存的 session 資料庫\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/auth0/node-jsonwebtoken\"\u003eJsonWebToken\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e產生 JWTs\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/dcodeIO/bcrypt.js\"\u003eBcryptjs\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e密碼加密\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/colinhacks/zod\"\u003eZod\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e驗證使用者的輸入\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://typegoose.github.io/typegoose/\"\u003eTypegoose\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e使用 TypeScript 優化 Mongoose 模型\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/motdotla/dotenv\"\u003eDotenv\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e讀取環境變數\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/expressjs/cors\"\u003eCors\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e允許資料能在前端與後端之間分享\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://lodash.com/\"\u003elodash\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e對 JavaScript 的功能擴充\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/wclr/ts-node-dev\"\u003ets-node-dev\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e當檔案變更時自動重啟\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e","title":"Node.js + JWT Authentication 專案(一) - 初始化專案"},{"content":" OAuth 2.0 最大的優勢是可擴展性與模塊化，但這樣的靈活性也導致於在不同的實現之間，會存在著相容性問題。當開發人員想在不同的系統上實現 OAuth 時，它提供很多的自定義選項容易讓人很困惑。\nOAuth 2.0 一共定義了 7 種授權類型，可以根據不同的情況與環境使用不同的模式：\nLegacy: 密碼模式 ( Password Grant ) Legacy: 隱含模式 ( Implicit Flow ) 授權碼 ( Authorization Code ) 刷新令牌 ( Refresh Token ) 客戶憑證 ( Client Credentials ) PKCE ( Proof Key for Code Exchange ) 設備碼 ( Device Code ) 起初，OAuth 設計是基於 HTTP 的，但實現方法的細節可以有很多種。\n在上一篇有提到，OAuth 裡定義的四種角色。其中的客戶端還可以分為兩種：\n前端客戶端：通常前端客戶端指的是瀏覽器 後端客戶端：後端客戶端指的是，實際需要取得存取權杖 ( Access Token ) 的服務 通常的流程為：\n資源擁有者 透過瀏覽器登入 ( 此步驟意同瀏覽器向資源擁有者授權請求 ) 授權伺服器 驗證身分並確認授權 授權給客戶端 ( 獲得存取權杖 ) 客戶端取得受保護的資源 客戶端提供資源擁有者服務 以上流程為 1.2. Protocol Flow。\nLegacy: 密碼模式 ( Password Grant ) +----------+ | Resource | | Owner | | | +----------+ v | Resource Owner (A) Password Credentials | v +---------+ +---------------+ | |\u0026gt;--(B)---- Resource Owner -------\u0026gt;| | | | Password Credentials | Authorization | | Client | | Server | | |\u0026lt;--(C)---- Access Token ---------\u0026lt;| | | | (w/ Optional Refresh Token) | | +---------+ +---------------+ Figure 5: Resource Owner Password Credentials Flow OAuth 有一個直接支援帳號密碼的方式。授權的結果還是由授權伺服器的權杖和資源伺服器決定，透過中央授權來限制存取權杖可以做什麼，但是直接使用帳號密碼這個方式並不是很好。\n使用時機：在其他模式下都不太適用時，再考慮這個模式。 Legacy: 隱含模式 ( Implicit Flow ) +----------+ | Resource | | Owner | | | +----------+ ^ | (B) +----|-----+ Client Identifier +---------------+ | -+----(A)-- \u0026amp; Redirection URI ---\u0026gt;| | | User- | | Authorization | | Agent -|----(B)-- User authenticates --\u0026gt;| Server | | | | | | |\u0026lt;---(C)--- Redirection URI ----\u0026lt;| | | | with Access Token +---------------+ | | in Fragment | | +---------------+ | |----(D)--- Redirection URI ----\u0026gt;| Web-Hosted | | | without Fragment | Client | | | | Resource | | (F) |\u0026lt;---(E)------- Script ---------\u0026lt;| | | | +---------------+ +-|--------+ | | (A) (G) Access Token | | ^ v +---------+ | | | Client | | | +---------+ Note: The lines illustrating steps (A) and (B) are broken into two parts as they pass through the user-agent. Figure 4: Implicit Grant Flow 在密碼模式 ( Password Grant ) 下適用於純前端環境；而在隱含模式 ( Implicit Flow ) 下就是前後端分離，而前端的部分 ( User-agent ) 即可視為一個完整的應用。\nOAuth Tools 實作 可以使用 OAuth.tools 這個線上服務來學習，點選 Demo: Implicit Flow 即可。\n可以看到 Start Flow 的 Start URL 為：\nhttps://login-demo.curity.io/oauth/v2/oauth-authorize? \u0026amp;client_id=demo-web-client \u0026amp;response_type=token \u0026amp;redirect_uri=https://oauth.tools/callback/implicit \u0026amp;state=1599045172021-mww \u0026amp;scope=read%20phone%20email client_id、response_type、redirect_uri 是必須的。\n按下 Run 後可能會要求登入 ( 隨便打即可 )，登入後就可以看到 Server Response ( 這個 Server Response 就是回傳的 URL 加上相關的資訊 )：\nhttps://oauth.tools/callback/implicit #access_token=_0XBPWQQ_76c0d4ce-5424-4757-a0d1-0be0bc936d66 \u0026amp;scope=read+phone+email \u0026amp;iss=https%3A%2F%2Flogin-demo.curity.io%2Foauth%2Fv2%2Foauth-anonymous \u0026amp;state=1599045172021-mww \u0026amp;token_type=bearer \u0026amp;expires_in=299 token_type=bearer 表示權杖為 bearer 類型。\n在隱含模式的設計下，資源擁有者使用的瀏覽器會與授權伺服器保持會話階段。簡單來說，就是使用者在登入中的情況下，可以隨時獲得新的存取權杖。\n為何稱為隱含模式？ 可以看到 redirect_uri 的 URL 指向的是客戶端。當瀏覽器接收到這個訊息後，會發送一個請求給用戶端，但不同的是，真正的用戶端是瀏覽器本身的 Web App，而不是提供 Web 服務的伺服器裡。也因此存取權杖不會發送到伺服器，而是保留在瀏覽器裡面，在瀏覽器的網路工具也幾乎是隱藏的。\n此模式雖然簡單，但將存取權杖暴露在使用者面前並不是非常好的做法，最好要快速清除訊息或是轉到其他頁面。\n不應該使用隱含模式 通常在處理完存取權杖後，應該要跳轉畫面或至少把資訊清除，因為權杖在網址上太容易取得了。而通常需要注意的是 XSS 跨站腳本攻擊。\n就算不是隱含模式，可能也有跳轉頁面的需要，在跳轉後，網址列上面的 Token 自然會消失。但是，為了要讓跳轉後的頁面也能夠知道存取權杖，在頁面跳轉時，可能會將存取權杖儲存在 localStorage 或 sessionStorage 裡。\n眾所皆知，將機敏資料儲存在 localStorage 或 sessionStorage 不是安全的作法，因為 XSS 攻擊可以很簡單的獲得裡面的資料。或許可以使用特別的加密方式，來降低存取權杖被猜到的風險。\n授權碼 ( Authorization Code ) +----------+ | Resource | | Owner | | | +----------+ ^ | (B) +----|-----+ Client Identifier +---------------+ | -+----(A)-- \u0026amp; Redirection URI ----\u0026gt;| | | User- | | Authorization | | Agent -+----(B)-- User authenticates ---\u0026gt;| Server | | | | | | -+----(C)-- Authorization Code ---\u0026lt;| | +-|----|---+ +---------------+ | | ^ v (A) (C) | | | | | | ^ v | | +---------+ | | | |\u0026gt;---(D)-- Authorization Code ---------\u0026#39; | | Client | \u0026amp; Redirection URI | | | | | |\u0026lt;---(E)----- Access Token -------------------\u0026#39; +---------+ (w/ Optional Refresh Token) Note: The lines illustrating steps (A), (B), and (C) are broken into two parts as they pass through the user-agent. Figure 3: Authorization Code Flow Authorization Code 是第一個在 RFC 6749 被提到的流程，所以有時候會被稱為 標準流程。\n它分成前端通訊 ( Frontchannel ) 和 後端通訊 ( Backchannel ) 兩個部分。與前兩個相比，在隱含模式下，後端通訊與前端通訊是併在一起的；密碼模式下，根本不存在前端通訊，所以資源擁有者需要高度信任客戶端。\n再複習一下前面的四種角色：\n資源擁有者 ( resource owner )：就是使用者 資源伺服器 ( resource server )：存放資料的伺服器 客戶端 ( client ) 前端客戶端：瀏覽器或 User-Agent 後端客戶端 授權伺服器 ( authorization server )： 除了資源伺服器以外，其他都會參與授權流程：\n前端通訊：指的是前端客戶端與授權伺服器 ( Authorization Server ) 交換訊息的過程。 後端通訊：指的是後端客戶端 ( Client ) 與 授權伺服器 ( Authorization Server ) 交換訊息的過程。 透過 OAuth.Tools 完成前端通訊 在 OAuth.Tools 頁面點選 Demo: Code Flow。\n按下 Run 一樣會進入到登入畫面。此時的 Start Flow：\nhttps://login-demo.curity.io/oauth/v2/oauth-authorize? \u0026amp;client_id=demo-web-client \u0026amp;response_type=code \u0026amp;redirect_uri=https://oauth.tools/callback/code \u0026amp;state=1599045135410-jFe \u0026amp;scope=openid%20profile%20read \u0026amp;ui_locales=en 登入結束後，一樣會根據 redirect_uri 回到指定的 URL。這時候會發送一個 Request 給 Web 伺服器，而這個伺服器就是客戶端。\n接著就是最重要的就是 query 裡面的 code，這個 code 會給客戶端，並讓客戶端拿著 code 去向授權伺服器兌換 ( redeem ) 存取權杖。\n這邊可以選擇按下 Redeem Code 按鈕來獲得存取權杖，又或者使用它所提供的 cURL 來獲得，只能選擇一種方法使用，因為一個 code 只能兌換一次。\n流程 最後來整理一下流程：\n在資源擁有者登入後驗證身分 資源擁有者代理 ( User-Agent ) 向系統申請一個 code ( 有時效性、只能使用一次 )，並且告訴授權伺服器，有人會在限定的時間內使用這個特殊密碼來獲得特定房間的鑰匙 資源擁有者代理 ( User-Agent ) 把這個特殊密碼給想要授權的對象 ( 客戶端 ) 客戶端使用 code，向授權伺服器兌換存取權杖 這個模式與特殊密碼很像。\n刷新令牌 ( Refresh Token ) +--------+ +---------------+ | |--(A)------- Authorization Grant ---------\u0026gt;| | | | | | | |\u0026lt;-(B)----------- Access Token -------------| | | | \u0026amp; Refresh Token | | | | | | | | +----------+ | | | |--(C)---- Access Token ----\u0026gt;| | | | | | | | | | | |\u0026lt;-(D)- Protected Resource --| Resource | | Authorization | | Client | | Server | | Server | | |--(E)---- Access Token ----\u0026gt;| | | | | | | | | | | |\u0026lt;-(F)- Invalid Token Error -| | | | | | +----------+ | | | | | | | |--(G)----------- Refresh Token -----------\u0026gt;| | | | | | | |\u0026lt;-(H)----------- Access Token -------------| | +--------+ \u0026amp; Optional Refresh Token +---------------+ Figure 2: Refreshing an Expired Access Token 使用 refresh_token 來取得 access_token 這是最簡單的一個模式了。也因為先決條件是必須要有 Refresh Token，所以無法單獨存在。\n上面的流程圖最重要的是步驟 (G) 和 (H)，因為如何取得 Refresh Token 的方式有很多種，不論是密碼模式或是 Authorization Code 模式下都有可能返回 refresh_token 了。\n延續上面授權碼 ( Authorization Code ) 所獲得的 Token：\n之後點選 OAuth.Tools 裡的 Demo: Refresh Tokens 來使用剛剛 Authorization Code 的 Refresh Token：\n我們可以選擇要使用哪個 Demo 的 refresh_token，之後按下 Refresh Token 就可以看到新產生的存取權杖。\nrefresh_token 的作用 Q：既然都透過密碼模式與 Authorization Code 模式取得存取權杖了，那為何還需要 refresh_token 呢？\nA：這是因為存取權杖是會過期的，如果每次過期都需要資源擁有者再登入一次，那是不是超麻煩的，所以才有這個 refresh_token，這同樣也像特殊密碼。但是與 Authorization Code 模式下獲得的那個 code 的特殊密碼不同的是，在限定的時間內，可以透過 refresh_token 獲取多次的存取權杖 (code 只能使用一次)。而且也與 access_token 不同，refresh_token 使用的地方是在客戶端與授權伺服器；access_token 使用的地方是在客戶端與資源伺服器。\n與 access_token 相比，refresh_token 使用的頻率沒有那麼高，相對也就不容易被竊取，存活的時間也比較久，藉由固定一段時間更新 access_token 的方式，也能降低一些安全問題。\n最後，refresh_token 可以使用幾次、多長時間、是否會返回 refresh_token，全部都是由授權伺服器決定的，也就是依照所需要的應用環境、存在的安全風險、使用不同的策略。你可能頻繁的更換 access_token 和 refresh_token，也可能一用就是一年。\n客戶憑證 ( Client Credentials ) +---------+ +---------------+ | | | | | |\u0026gt;--(A)- Client Authentication ---\u0026gt;| Authorization | | Client | | Server | | |\u0026lt;--(B)---- Access Token ---------\u0026lt;| | | | | | +---------+ +---------------+ Figure 6: Client Credentials Flow 這個模式很特別，它可能會與其他模式並用以外，最特別的是，如果只是單純使用它，是完全不需要資源擁有者參與的。\n在 OAuth.Tools 頁面點選 Demo: Client Credentials Flow。\n直接按下 Run 後可以看到回傳的結果：\n可以發現它與隱含模式一樣都沒有 refresh_token，這是因為 client_secret 只有客戶端擁有，不會送到瀏覽器去參與前端通訊。也因為不存在前端通訊，自然就不會知道資源擁有者是誰了。\n也因為 client_secret 只有客戶端擁有，所以客戶端可以隨時取得 access_token。這就像客戶端建立了一個帳號系統，client_id 就是帳號；client_secret就是密碼。\nPKCE ( Proof Key for Code Exchange ) +-------------------+ | Authz Server | +--------+ | +---------------+ | | |--(A)- Authorization Request ----\u0026gt;| | | | | + t(code_verifier), t_m | | Authorization | | | | | | Endpoint | | | |\u0026lt;-(B)---- Authorization Code -----| | | | | | +---------------+ | | Client | | | | | | +---------------+ | | |--(C)-- Access Token Request ----\u0026gt;| | | | | + code_verifier | | Token | | | | | | Endpoint | | | |\u0026lt;-(D)------ Access Token ---------| | | +--------+ | +---------------+ | +-------------------+ Figure 2: Abstract Protocol Flow PKCE 是 Authorization Code 的安全強化版。\n在整個過程添加了兩個動作：產生 code_verifier 和 code_challenge，並且在最後透過 code_challenge 驗證 code_verifier。最大的目的就是建立前端通訊與後端通訊的關聯。\n原始的風險 Authorization Code 的流程是：\n在資源擁有者登入後驗證身分 資源擁有者代理 ( User-Agent ) 向系統申請一個 code 資源擁有者代理 ( User-Agent ) 將 code 轉給客戶端 客戶端使用 code，向授權伺服器兌換存取權杖 可以看到上面的流程，code 可能透過網路傳遞了很多次。傳遞越多次就代表洩漏的風險就越高，攻擊者就有可能在這中間取得存取權杖。\n以下是惡意應用竊取 code 的方式：\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~+ | End Device (e.g., Smartphone) | | | | +-------------+ +----------+ | (6) Access Token +----------+ | |Legitimate | | Malicious|\u0026lt;--------------------| | | |OAuth 2.0 App| | App |--------------------\u0026gt;| | | +-------------+ +----------+ | (5) Authorization | | | | ^ ^ | Grant | | | | \\ | | | | | | \\ (4) | | | | | (1) | \\ Authz| | | | | Authz| \\ Code | | | Authz | | Request| \\ | | | Server | | | \\ | | | | | | \\ | | | | | v \\ | | | | | +----------------------------+ | | | | | | | (3) Authz Code | | | | Operating System/ |\u0026lt;--------------------| | | | Browser |--------------------\u0026gt;| | | | | | (2) Authz Request | | | +----------------------------+ | +----------+ 在 (4) 這個步驟，惡意應用 ( Malicious App ) 就可能截取到 code。就算不是直接截取，也可能通過這種方式來猜測到 code。\n所以，為了降低被攻擊的機會，可以添加一些加密方式，來提升攻擊的難度。配合使用 Client Credentials Flow 或許是一個方法，因為依照設計 client_secret 只有客戶端擁有，並且只在客戶端與授權伺服器間流通。但這樣做的前提為客戶端是已經被認可的客戶端，這還是沒辦法證明客戶端、資源擁有者、使用 code 兌換存取權杖 都是同一個人。\n解決方法 那要如何讓前端通訊與後端通訊建立更明確的關係？客戶端能用什麼方式來證明是自己是授權的那一個？\n以下是流程：\n客戶端告訴瀏覽器證明自己的方式，並讓瀏覽器將這個訊息告訴授權伺服器。 瀏覽器取得特殊密碼 code，並與授權伺服器約定好，在未來，會有一個人帶著這個 code 與一個能證明自己就是這個人的方法來找你。 瀏覽器將 code 交給客戶端。 客戶端帶著 code 與證明自己的方式訪問授權伺服器。 授權伺服器會檢查 code 與證明的方式，如果符合，就會將存取權杖交給客戶端。 那要如何證明自己的身分呢？那就是有一個很困難的問題，這個問題的答案只有自己知道。而且這個題目的答案很難推敲出來，從題目證明答案是否正確很容易。\n這個方式就是單向雜湊函數( One-way Hash Function )。從一個方向運算很簡單，但反過來很難。在 RFC 7636 － 4.6 就設定了 code_challenge 是由 SHA-256 來組成這個難題，只要 code_verifier 正確，就能夠證明自己的身分了。\n使用 OAuth Tools 實作 在 OAuth.Tools 頁面點選 Demo: Code Flow，並勾選 Use PKCE 的選項。\n接著，可以看到 Start Flow 多出 code_challenge 與 code_challenge_method：\nhttps://login-demo.curity.io/oauth/v2/oauth-authorize? \u0026amp;client_id=demo-web-client \u0026amp;response_type=code \u0026amp;redirect_uri=https://oauth.tools/callback/code \u0026amp;state=1599045135410-jFe \u0026amp;scope=openid%20profile%20read --- \u0026amp;code_challenge=mSrwhFdk8l_oSJvSdiyLtVe2SLf5o0hvH4h4xOnLpAU \u0026amp;code_challenge_method=S256 --- \u0026amp;prompt=login \u0026amp;ui_locales=en \u0026amp;nonce=1599046102647-dv4 並且在後端通訊 ( 也就是兌換存取權杖時 ) 將答案告訴授權伺服器：\ncurl -Ss -X POST \\ https://login-demo.curity.io/oauth/v2/oauth-token \\ -H \u0026#39;Authorization: Basic ZGVtby13ZWItY2xpZW50OjZrb3luOUtwUnVvZll0MlU=\u0026#39; \\ -H \u0026#39;Content-Type: application/x-www-form-urlencoded\u0026#39; \\ -d \u0026#39;grant_type=authorization_code\u0026amp;redirect_uri=https%3A%2F%2Foauth.tools%2Fcallback%2Fcode\u0026amp;code=rtNEXkJGpsiaiPd198FK8teHJsjOAYWm\u0026amp; code_verifier=1Ex9PnVFClsom1mlAKVyRSTKmXpKi26a8qXfK8KSBdNJgh3hNxdrwtDq4uj01Rt3\u0026#39; 如果驗證失敗，不會通過授權並且 code 會被認會可能已洩漏，所以就不能再使用。如果通過，就能獲得存取權杖。\n設備碼 ( Device Code ) +----------+ +----------------+ | |\u0026gt;---(A)-- Client Identifier ---\u0026gt;| | | | | | | |\u0026lt;---(B)-- Device Code, ---\u0026lt;| | | | User Code, | | | Device | \u0026amp; Verification URI | | | Client | | | | | [polling] | | | |\u0026gt;---(E)-- Device Code ---\u0026gt;| | | | \u0026amp; Client Identifier | | | | | Authorization | | |\u0026lt;---(F)-- Access Token ---\u0026lt;| Server | +----------+ (\u0026amp; Optional Refresh Token) | | v | | : | | (C) User Code \u0026amp; Verification URI | | : | | v | | +----------+ | | | End User | | | | at |\u0026lt;---(D)-- End user reviews ---\u0026gt;| | | Browser | authorization request | | +----------+ +----------------+ Figure 1: Device Authorization Flow Device Code 的流程與前面幾個都不相同。以往都是從登入開始，然後跳轉頁面回到 App ( 客戶端 )。也就是先有前端通訊，再有後端通訊。\n但 Device Code 不是由資源擁有者發起，而是客戶端發起。大致流程為：\n客戶端發起，向授權伺服器取得 device_code 和 user_code。 客戶端將 user_code 交給資源擁有者，自己則保留 device_code。 資源擁有者透過 Endpoint 與 user_code 進行授權。 客戶端使用 device_code 訪問授權伺服器是否有人授權給它。 user_code 像是之前的特殊密碼；device_code 更像是 session。\n可以到 OAuth 2.0 Playground 嘗試。\n首先，獲得來自授權伺服器的所有資訊：\n{ \u0026#34;device_code\u0026#34;: \u0026#34;NGU5OWFiNjQ5YmQwNGY3YTdmZTEyNzQ3YzQ1YSA\u0026#34;, \u0026#34;user_code\u0026#34;: \u0026#34;BDWD-HQPK\u0026#34;, \u0026#34;verification_uri\u0026#34;: \u0026#34;https://example.okta.com/device\u0026#34;, \u0026#34;interval\u0026#34;: 5, \u0026#34;expires_in\u0026#34;: 1800 } 當第一次點 poll 時，會看到：\nHTTP/1.1 400 Bad Request { \u0026#34;error\u0026#34;: \u0026#34;authorization_pending\u0026#34; } 這表示資源擁有者還沒有完成登入授權的請求，所以授權伺服器會回傳等待授權。當資源擁有者完成請求後，客戶端就可以拿到存取權杖了：\nHTTP/1.1 200 OK { \u0026#34;token_type\u0026#34;: \u0026#34;Bearer\u0026#34;, \u0026#34;access_token\u0026#34;: \u0026#34;RsT5OjbzRn430zqMLgV3Ia\u0026#34;, \u0026#34;expires_in\u0026#34;: 3600, \u0026#34;refresh_token\u0026#34;: \u0026#34;b7a3fac6b10e13bb3a276c2aab35e97298a060e0ede5b43ed1f720a8\u0026#34; } 使用例子 使用 Device Code 的方式隨處可見：\n使用 QR Code 登入的應用 ( 特殊連接登入的應用 ) QR Code 同樣是一個特殊連結。 結語 對我來說，要弄清楚其中運作的流程是需要一點想像力的，也多虧有 用Keycloak學習身份驗證與授權 這一系列的文章幫助我理解。\nReference 用Keycloak學習身份驗證與授權 👍 RFC 6749 RFC 7637 RFC 8628 OAuth Tools OAuth2 Playground ","permalink":"https://et860525.github.io/posts/oauth-grant/","summary":"OAuth 2.0 最大的優勢是可擴展性與模塊化，但這樣的靈活性也導致於在不同的實現之間，會存在著相容性問題。當開發人員想在不同的系統上實現 OAuth 時，它提供很多的自定義選項容易讓人很困惑。\nOAuth 2.0 一共定義了 7 種授權類型，可以根據不同的情況與環境使用不同的模式：\nLegacy: 密碼模式 ( Password Grant ) Legacy: 隱含模式 ( Implicit Flow ) 授權碼 ( Authorization Code ) 刷新令牌 ( Refresh Token ) 客戶憑證 ( Client Credentials ) PKCE ( Proof Key for Code Exchange ) 設備碼 ( Device Code ) 起初，OAuth 設計是基於 HTTP 的，但實現方法的細節可以有很多種。\n在上一篇有提到，OAuth 裡定義的四種角色。其中的客戶端還可以分為兩種：\n前端客戶端：通常前端客戶端指的是瀏覽器 後端客戶端：後端客戶端指的是，實際需要取得存取權杖 ( Access Token ) 的服務 通常的流程為：\n資源擁有者 透過瀏覽器登入 ( 此步驟意同瀏覽器向資源擁有者授權請求 ) 授權伺服器 驗證身分並確認授權 授權給客戶端 ( 獲得存取權杖 ) 客戶端取得受保護的資源 客戶端提供資源擁有者服務 以上流程為 1.","title":"OAuth Grant"},{"content":" OAuth 是一個開放標準的授權協議，它允許使用者讓第三方應用存取該使用者在某網站儲存的私密資源。\n試想有一棟房子，裡面有很多個房間，裡面有一位房東 ( 使用者 ) 擁有一把萬能鑰匙，可以開啟所有的房間門。除此之外，這把萬能鑰匙還有一個作用，就是可以產出特定門的鑰匙，而產生出來的鑰匙可以交給其他人，這樣其他人就可以進出特定的房間，這個動作就是「授權」。\nOAuth 2.0 是 OAuth 的進化版，它是授權框架 ( authorization framework )，允許應用向使用者請求授權，然後取得 Token，並且用它來訪問資源。\nThe OAuth 2.0 authorization framework enables a third-party application to obtain limited access to an HTTP service, either on behalf of a resource owner by orchestrating an approval interaction between the resource owner and the HTTP service, or by allowing the third-party application to obtain access on its own behalf. － RFC 6749\nOAuth 2.0 授權框架能讓第三方應用以有限的方式訪問 HTTP 服務，建構資源擁有者與 HTTP 服務之間的許可交互機制，或是通過第三方應用代表自己訪問服務。\n作為一個授權框架，首先要先了解各個在 OAuth 裡定義的四種角色 ( RFC 6794 - Roles )：\n資源擁有者 ( resource owner )：能將訪問授權委託給出去，資源擁有者指的是使用者本身，又或是系統中的帳號。 資源伺服器 ( resource server )：託管受保護資源的伺服器，接受訪問 Token 並回應受保護的資源。 客戶端 ( client )：指的就是代表資源擁有者訪問資源伺服器的應用。 授權伺服器 ( authorization server )：驗證資源所有者的身分並發放訪問 Token。 OAuth 不是什麼 OAuth 不是身分驗證協議：OAuth 重點是授權而不是進行身分驗證。 OAuth 沒有定義用戶對用戶的授權機制 OAuth 沒有定義授權處理機制：OAuth 定義一些授權框架或流程，但不定義授權的內容。 OAuth 沒有定義權杖格式：OAuth 協議明確申明了權杖的內容，對於客戶端是完全不透明的。但接受權杖處理的服務，就必須要理解權杖，這表示授權伺服器僅產生權杖，理解權杖的這件事情都依賴於資源伺服器。使用上面的例子：萬能鑰匙產生新的鑰匙，但這把鑰匙能不能使用全部都由門鎖決定，與獲得鑰匙的人、房東都沒有關係。 OAuth 2.0 不定義加密方法：許多服務都會要求客戶端支援 HTTPS，但框架本身是不關心這個部分，也不管權杖如何簽名、加密、驗證。 OAuth 2.0 不是單體協議：分成多個定義和流程，每個定義和流程都有各自的場景。 OAuth 1.0 OAuth 2.0 並不相容於 OAuth 1.0，現在看到的 OAuth 大多都是直接指 OAuth 2.0。2009年4月23日，OAuth 宣告了一個1.0協定的安全漏洞。\nOAuth 2.0 概念 假裝自己是用戶 使用帳號密碼 有一支程式能幫你收發信件，只需要告訴它你信箱的帳號密碼，這表示你完全信任它。也不用自己寫程式，Gmail 就有這一個服務了，假如你想要讓 Gmail 收發來自 Yahoo 的信件，只要告訴它你的 Yahoo 帳號密碼就行，這也表示你信任 Google 的服務。\n特殊密碼 如果這種代理( proxy ) 的方式不只是在一般的軟體，而是作業系統或是硬體裡。\n如果需要在公司電腦或公共電腦登入，或許還是使用 Google 的服務，但實際上中間還通過好幾層的代理。首先，在硬體、作業系統上可能會有安裝鍵盤紀錄器之類的東西，瀏覽器也是一個代理，但使用的是可信任的瀏覽器嗎？\n這時候就可以與服務約定一種「特殊密碼」，只能使用一次的密碼 ( OTP, One Time Password )。目前更常見的是雙重認證 ( 2FA, Two Factor Authentication )，實際上的形式為：\n簡訊或信箱驗證：一組限時且只能使用一次的密碼 特殊連接驗證：一個特殊的連接，該連接有時效性，且只能存取一次 透過時間產生特殊密碼：TOTP, Time-base One Time Password 透過雜湊產生特殊密碼：HOTP, HMAC-based One Time Password 與系統服務約定好數組一次性密碼：例如救援碼 開發者權杖 在開發的應用下，你本身就是開發者之一，但是在內部可能會有控制的問題，所以還需要一個看門人 ( gatekeeper ) 來檢查是否有權限操作。\n委託授權 以上都是整份授權，都還沒有把權限拆分更小的部分並分開授權，例如只授權存取角色、Email 地址、使用者資訊，並且產生一組特殊密碼。\n結語 過去，在使用 Passport.js 寫專案時，其實都沒有真正的了解它實際的概念。看到現在，只要能釐清各個角色在之中做的事情，對於理解上就不會太過複雜了。\nReference 用Keycloak學習身份驗證與授權 ","permalink":"https://et860525.github.io/posts/oauth-first-look/","summary":"OAuth 是一個開放標準的授權協議，它允許使用者讓第三方應用存取該使用者在某網站儲存的私密資源。\n試想有一棟房子，裡面有很多個房間，裡面有一位房東 ( 使用者 ) 擁有一把萬能鑰匙，可以開啟所有的房間門。除此之外，這把萬能鑰匙還有一個作用，就是可以產出特定門的鑰匙，而產生出來的鑰匙可以交給其他人，這樣其他人就可以進出特定的房間，這個動作就是「授權」。\nOAuth 2.0 是 OAuth 的進化版，它是授權框架 ( authorization framework )，允許應用向使用者請求授權，然後取得 Token，並且用它來訪問資源。\nThe OAuth 2.0 authorization framework enables a third-party application to obtain limited access to an HTTP service, either on behalf of a resource owner by orchestrating an approval interaction between the resource owner and the HTTP service, or by allowing the third-party application to obtain access on its own behalf. － RFC 6749","title":"理解 OAuth"},{"content":"WebSocket 是由 HTML 5 所提供用於讓瀏覽器與伺服器進行互動通訊的技術。\nWebSocket 只需要連線一次，就能保持與伺服器的雙向溝通，無須重新發送 Request，這也讓回應更即時與快速。\n歷史 在早期，網站為了實現推播的技術，都是使用輪詢 ( polling )。所謂的輪詢就是瀏覽器每隔一段時間 ( 如每秒 ) 像伺服器發出 HTTP Request，伺服器便會回傳最新的資料給客戶端，很明顯的缺點就是瀏覽器必須不斷的發出 Request。\nWhy WebSocket ? 雙向溝通：從以上可以得知，在以前都是由 Client 端進行「單向」發送 Request，而無法由 Server 主動發出 Request。而 WebSocket 協定可以讓 Server 端主動向 Client 推播資料，以此實現「雙向溝通」 實際使用：推播、即時聊天室、共同編輯 使用 WebSocket WebSocket 是由瀏覽器使用 JavaScript 來建立的，發起一個 HTTP Request。一般 WebSocket 請求網址為：\nws://example.com/wsapi 經過 SSL 加密後就會變成：\nwss://secure.example.com/wsapi 交握 ( Handshaking ) Websocket 通過 HTTP/1.1 協定進行交握。\n客戶端 ( Client ) Request：\nGET /chat HTTP/1.1 Host: server.example.com Upgrade: websocket Connection: Upgrade Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ== Origin: http://example.com Sec-WebSocket-Protocol: chat, superchat Sec-WebSocket-Version: 13 GET /chat HTTP/1.1 使用 HTTP/1.1 協定進行交握 Upgrade: websocket 表示客戶端想升級為 websocket 協定 Connection: Upgrade 表示客戶端想連接升級 Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ== 計算 SHA-1 摘要，之後進行 Base64 編碼，該結果會成為伺服器回傳「Sec-WebSocket-Accept」頭的值並返回給客戶端，以避免普通 HTTP 被誤認為 WebSocket 協定 ( 每一次握手隨機產生 ) Origin: http://example.com 客戶端的 URL Sec-WebSocket-Protocol: chat, superchat URL 下不同 Server 需要的協議 Sec-WebSocket-Version: 13 支援的Websocket版本 伺服器 ( Server ) Response：\nHTTP/1.1 101 Switching Protocols Upgrade: websocket Connection: Upgrade Sec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo= Sec-WebSocket-Protocol: chat HTTP/1.1 101 Switching Protocols 建立成功 Sec-WebSocket-Protocol: chat 伺服器端使用的協議 Server 端：建立 WebSocket 環境 先安裝兩個套件：\npnpm install express pnpm install ws 安裝後，建立 server.js 檔案：\nconst express = require(\u0026#39;express\u0026#39;) const ServerSocket = require(\u0026#39;ws\u0026#39;).Server // 引用 Server // 指定一個 port const PORT = 8080 // 建立 express 物件並用來監聽 8080 port const server = express() .listen(PORT, () =\u0026gt; console.log(`[Server] Listening on https://localhost:${PORT}`)) // 透過 ServerSocket 開啟 WebSocket 的服務 const wss = new ServerSocket({ server }) // Connection opened wss.on(\u0026#39;connection\u0026#39;, ws =\u0026gt; { console.log(\u0026#39;Client connected\u0026#39;) // Connection closed ws.on(\u0026#39;close\u0026#39;, () =\u0026gt; { console.log(\u0026#39;Close connected\u0026#39;) }) }) 使用以下指令執行 Server：\nnode server.js Client 端：連線到 WebSocket Server 建立完 Server 後，接下來要建立 Client 來連線到 WebSocket Server。建立一個新的專案，裡面會有 index.html 與 index.js 兩個檔案。\n首先，先建立 index.html：\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- Connect or Disconnect WebSocket Server --\u0026gt; \u0026lt;button id=\u0026#34;connect\u0026#34;\u0026gt;Connect\u0026lt;/button\u0026gt; \u0026lt;button id=\u0026#34;disconnect\u0026#34;\u0026gt;Disconnect\u0026lt;/button\u0026gt; \u0026lt;!-- Send Message to Server --\u0026gt; \u0026lt;div\u0026gt; Message: \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;sendMsg\u0026#34; \u0026gt;\u0026lt;button id=\u0026#34;sendBtn\u0026#34;\u0026gt;Send\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- Import index.js after UI rendered --\u0026gt; \u0026lt;script src=\u0026#39;./index.js\u0026#39;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 新增一個 index.js 檔案來處理邏輯：\nvar ws // 監聽 click 事件 document.querySelector(\u0026#39;#connect\u0026#39;)?.addEventListener(\u0026#39;click\u0026#39;, (e) =\u0026gt; { console.log(\u0026#39;[click connect]\u0026#39;) connect() }) document.querySelector(\u0026#39;#disconnect\u0026#39;)?.addEventListener(\u0026#39;click\u0026#39;, (e) =\u0026gt; { console.log(\u0026#39;[click disconnect]\u0026#39;) disconnect() }) document.querySelector(\u0026#39;#sendBtn\u0026#39;)?.addEventListener(\u0026#39;click\u0026#39;, (e) =\u0026gt; { const msg = document.querySelector(\u0026#39;#sendMsg\u0026#39;) sendMessage(msg?.value) }) function connect() { // Create WebSocket connection ws = new WebSocket(\u0026#39;ws://localhost:8080\u0026#39;) // 在開啟連線時執行 ws.onopen = () =\u0026gt; console.log(\u0026#39;[open connection]\u0026#39;) } function disconnect() { ws.close() // 在關閉連線時執行 ws.onclose = () =\u0026gt; console.log(\u0026#39;[close connection]\u0026#39;) } 如果使用 console.log(ws) 可以看到物件：\nreadyState 有四種 code：\n0：連接尚未建立 1：連接建立，可以進行通訊 2：連接正在進行關閉 3：連接已經關閉或連接打不開 這裡可以看到 WebSocket 有四個事件：\nonopen onerror onclose onmessage 監聽 WebSocket 事件 open 與 WebSocket Server 連接建立時會觸發：\nws.addEventListener(\u0026#39;open\u0026#39;, function() { console.log(\u0026#39;連結建立成功。\u0026#39;) }) error 通信錯誤時觸發\nclose 關閉 WebSocket Server 連線時觸發：\nws.addEventListener(\u0026#39;close\u0026#39;, function() { console.log(\u0026#39;連結關閉。\u0026#39;) }) message 監聽由 Server 主動發來的訊息：\nws.addEventListener(\u0026#39;message\u0026#39;, function(e) { var msg = JSON.parse(e.data); console.log(msg) }) 以下有更詳細的 Message 處理。\n處理 Message 因為 WebSocket 可以雙向溝通，所以 Server 端可以發送訊息給 Client 端，Client 端也可以發送訊息給 Server 端。\nServer 端 Server 端使用 send 發送訊息，Client 透過監聽 message 事件來接收訊息：\n// Connection opened wss.on(\u0026#39;connection\u0026#39;, ws =\u0026gt; { console.log(\u0026#39;Client connected\u0026#39;) // Listen for messages from client ws.on(\u0026#39;message\u0026#39;, data =\u0026gt; { console.log(\u0026#39;[Message from client]: \u0026#39;, data) // Send message to client ws.send(\u0026#39;[Get message from server]\u0026#39;) }) // ... }) Client 端 Clinet 端使用 send 發送訊息，Server 端使用 onmessage 接收訊息：\n// Client: 監聽 click 事件 document.querySelector(\u0026#39;#sendBtn\u0026#39;)?.addEventListener(\u0026#39;click\u0026#39;, (e) =\u0026gt; { const msg = document.querySelector(\u0026#39;#sendMsg\u0026#39;) sendMessage(msg?.value) }) // Server: Listen for messages function sendMessage(msg) { // Send messages to Server ws.send(msg) // Listen for messages from Server ws.onmessage = event =\u0026gt; console.log(\u0026#39;[send message]\u0026#39;, event) } 一個簡單的即時聊天室 以下的程式碼實作會放在 et860525/websocket-test\nWebSocket 可以運用在聊天室等功能，實現一個 Server 同時讓多個 Client 連線，並讓 Client A 傳送訊息給 Server 的同時，讓 Client B 接收來自 Server 的訊息。\n這時候就要使用廣播功能，首先透過 ws 提供的方法來讓 Client 取得目前所有其他 Clients 的資訊，再使用 forEach 迴圈送出訊息給每一個 Client：\n// Connection opened wss.on(\u0026#39;connection\u0026#39;, ws =\u0026gt; { console.log(\u0026#39;Client connected\u0026#39;) // Listen for messages from client ws.on(\u0026#39;message\u0026#39;, data =\u0026gt; { console.log(\u0026#39;[Message from client]: \u0026#39;, data) // Get clients who connected let clients = wss.clients // Use loop for sending messages to each client clients.forEach(client =\u0026gt; { client.send(\u0026#39;[Broadcast][Get message from server]\u0026#39;) }) }) // ... }) 那要如何給不同的 Client 一個獨一無二的 ID 呢？\n根據 unique identifier for each client request to websocket server，這裡可以直接取得 request header 中的 sec-websocket-key 給每個 Client 不同的 ID：\nwss.on(\u0026#39;connection\u0026#39;, (ws, req) =\u0026gt; { var id = req.headers[\u0026#39;sec-websocket-key\u0026#39;] // Do something... }) 以下為完整的程式碼：\nServer 端 server.js\n// import library const express = require(\u0026#39;express\u0026#39;) const ServerSocket = require(\u0026#39;ws\u0026#39;).Server // 引用 Server const PORT = 8080 // 建立 express 物件並用來監聽 8080 port const server = express() .listen(PORT, () =\u0026gt; console.log(`[Server] Listening on https://localhost:${PORT}`)) // 建立實體，透過 ServerSocket 開啟 WebSocket 的服務 const wss = new ServerSocket({ server }) // Connection opened wss.on(\u0026#39;connection\u0026#39;, (ws, req) =\u0026gt; { ws.id = req.headers[\u0026#39;sec-websocket-key\u0026#39;].substring(0, 8) ws.send(`[Client ${ws.id} is connected!]`) // Listen for messages from client ws.on(\u0026#39;message\u0026#39;, data =\u0026gt; { console.log(\u0026#39;[Message from client] data: \u0026#39;, data) // Get clients who has connected let clients = wss.clients // Use loop for sending messages to each client clients.forEach(client =\u0026gt; { client.send(`${ws.id}: ` + data) }) }) // Connection closed ws.on(\u0026#39;close\u0026#39;, () =\u0026gt; { console.log(\u0026#39;[Close connected]\u0026#39;) }) }) 嘗試使用 TypeScript 來建構 Server 端 ( server.ts )：\nimport express from \u0026#39;express\u0026#39;; import WebSocket, { Server } from \u0026#39;ws\u0026#39;; const PORT = 8080; // 建立 express 物件並用來監聽 8080 port const server = express().listen(PORT, () =\u0026gt; console.log(`[Server] Listening on https://localhost:${PORT}`) ); // 透過 Server 開啟 WebSocket 的服務 const wss = new Server({ server: server }); // Connection opened wss.on(\u0026#39;connection\u0026#39;, (ws: WebSocket, req) =\u0026gt; { let id = req.headers[\u0026#39;sec-websocket-key\u0026#39;]; if (id) id = id.substring(0, 8); ws.send(`[Client ${id} is connected!]`); // Listen for messages from client ws.on(\u0026#39;message\u0026#39;, (data) =\u0026gt; { console.log(\u0026#39;[Message from client] data: \u0026#39;, data); // Get clients who has connected let clients = wss.clients; // Use loop for sending messages to each client clients.forEach((client) =\u0026gt; { client.send(`${id}: ` + data); }); }); // Connection closed ws.on(\u0026#39;close\u0026#39;, () =\u0026gt; { console.log(\u0026#39;[Close connected]\u0026#39;); }); }); Client 端 index.js\nvar ws // 監聽 click 事件 document.querySelector(\u0026#39;#connect\u0026#39;)?.addEventListener(\u0026#39;click\u0026#39;, (e) =\u0026gt; { connect() }) document.querySelector(\u0026#39;#disconnect\u0026#39;)?.addEventListener(\u0026#39;click\u0026#39;, (e) =\u0026gt; { disconnect() }) document.querySelector(\u0026#39;#sendBtn\u0026#39;)?.addEventListener(\u0026#39;click\u0026#39;, (e) =\u0026gt; { const msg = document.querySelector(\u0026#39;#sendMsg\u0026#39;) sendMessage(msg?.value) }) function connect() { // Create WebSocket connection ws = new WebSocket(\u0026#39;ws://localhost:8080\u0026#39;) // 也可以連線到指定的 IP // ws = new WebSocket(\u0026#39;ws://192.168.17.35:58095\u0026#39;) // 在開啟連線時執行 ws.onopen = () =\u0026gt; { console.log(\u0026#39;[open connection]\u0026#39;) // Listen for messages from Server ws.onmessage = event =\u0026gt; { console.log(`[Message from server]:\\n %c${event.data}` , \u0026#39;color: blue\u0026#39;) } } } function sendMessage(msg) { // Send messages to Server ws.send(msg) } function disconnect() { ws.close() // 在關閉連線時執行 ws.onclose = () =\u0026gt; console.log(\u0026#39;[close connection]\u0026#39;) } Socket vs WebSocket vs Socket.io Socket 使用者可以透過 Socket 來操作 TCP/IP 協議 定義在 傳輸層跟應用層之間 傳輸方式為 stream 傳輸載體為 binary WebSocket 為了讓 Web 即時雙向通訊而創造的協議 屬於應用層 瀏覽器底層使用 socket 當作通訊界面 載體有兩種：binary或text，只能擇一使用 Socket.io Socket.io 是一個框架一個套件 建立在 WebSocket 上的套件，支持代理和負載平衡器 兩部分組成：Server 端為 Node.js；Client 端為 JavaScript socket.io並沒有任何連線功能，主要是靠核心 engine.io 來連接伺服器與客戶端 結語 研究了一下 WebSocket 技術，其重點為：客戶端可以不用為了確認資料在伺服器裡的狀態，而不斷的送出 Request，而是當伺服器裡的資料狀態更新時，伺服器可以主動的將資料推播給客戶端。\nReference 淺談 WebSocket 協定：實作一個簡單的即時聊天室吧！ JavaScript | WebSocket 讓前後端沒有距離 Socket，Websocket，Socket.io的差異 WebSocket 基本介紹及使用筆記 ","permalink":"https://et860525.github.io/posts/websocket-first-look/","summary":"\u003cp\u003e\u003ca href=\"https://zh.wikipedia.org/zh-tw/WebSocket\"\u003eWebSocket\u003c/a\u003e 是由 \u003ca href=\"https://zh.wikipedia.org/zh-tw/HTML5\"\u003eHTML 5\u003c/a\u003e 所提供用於讓瀏覽器與伺服器進行互動通訊的技術。\u003c/p\u003e\n\u003cp\u003eWebSocket 只需要連線一次，就能保持與伺服器的\u003cstrong\u003e雙向溝通\u003c/strong\u003e，無須重新發送 Request，這也讓回應更即時與快速。\u003c/p\u003e","title":"初試 WebSocket"},{"content":"當我開始完善各個功能時，就發現回傳 view 所需要的函式不只有 render，在某些時候還是要使用 redirect，而當這樣會有兩種格式要回傳時，我就會建立 Response Object 來制定回傳的格式，並且在 route.base 中就要多一個專門處理 redirect 的函式。\n當這些都完成後，就可以開始實作網頁的功能了，在這篇文章裡我會實作 MenuItem 的 CRUD。\nGithub：et860525/restaurant-management\nResponse Object 首先，Response object 會將 Contoller 所回傳的資料做成統一的格式，並能讓 Route 使用。以下將兩個 Response object 放到 src/commom/response/response.object.ts：\nexport class renderResponseObject { public readonly view: string = \u0026#39;index\u0026#39;; public readonly data: any = null; constructor(options: { view: string; data?: any }) { this.view = options.view || this.view; this.data = options.data || this.data; } } export class redirectResponseObject { public readonly status: number = 302; public readonly url: string = \u0026#39;/\u0026#39;; constructor(options: { url: string; status?: number }) { this.url = options.url || this.url; this.status = options.status || this.status; } } 根據 render 與 redirect 會使用到的參數製作成 obejct，完成後再到 controller.base 新增相對應的函式來建立 Response object 並回傳：\nimport { renderResponseObject, redirectResponseObject, } from \u0026#39;../common/response/response.object\u0026#39;; export abstract class ControllerBase { public formatResponse(view: string, data?: any) { const responseObject = new renderResponseObject({ view, data }); return responseObject; } public formatRedirectResponse(url: string, status?: number) { const responseObject = new redirectResponseObject({ url, status }); return responseObject; } } 由 Route 會獲得從 Controll 回傳來的 Response object，所以要更改 route.base 的程式碼：\nimport { renderResponseObject, redirectResponseObject } from \u0026#39;../common/response/response.object\u0026#39;; export abstract class RouteBase { // 略... protected responseHandler( method: ( req: Request, res: Response, next: NextFunction ) =\u0026gt; Promise\u0026lt;renderResponseObject\u0026gt; ) { return (req: Request, res: Response, next: NextFunction) =\u0026gt; { method .call(this.controller, req, res, next) .then((obj) =\u0026gt; res.render(obj.view, obj.data)) .catch((err) =\u0026gt; next(err)); }; } protected responseRedirectHandler( method: ( req: Request, res: Response, next: NextFunction ) =\u0026gt; Promise\u0026lt;redirectResponseObject\u0026gt; ) { return (req: Request, res: Response, next: NextFunction) =\u0026gt; { method .call(this.controller, req, res, next) .then((obj) =\u0026gt; res.redirect(obj.status, obj.url)) .catch((err) =\u0026gt; next(err)); }; } } 接下來就要開始完善 MenuItem 的各種功能。\nMenuItem Route 以下是讓使用者可以對菜單進行 CRUD 的動作，首先先新增路由，到 main/menu/menuItem.routing.ts：\nimport express from \u0026#39;express\u0026#39;; import { RouteBase } from \u0026#39;../../base/route.base\u0026#39;; import { MenuItemController } from \u0026#39;./menuItem.controller\u0026#39;; export class MenuItemRoute extends RouteBase { protected controller!: MenuItemController; constructor() { super(); } protected initial(): void { this.controller = new MenuItemController(); super.initial(); } protected registerRoute(): void { this.router.get( \u0026#39;/menuItems\u0026#39;, this.responseHandler(this.controller.get_many) ); this.router .route(\u0026#39;/menuItems/create\u0026#39;) .get(this.responseHandler(this.controller.form)) .post( express.json(), this.responseRedirectHandler(this.controller.create) ); this.router.get( \u0026#39;/menuItems/:id\u0026#39;, this.responseHandler(this.controller.get) ); this.router .route(\u0026#39;/menuItems/:id/delete\u0026#39;) .get(this.responseHandler(this.controller.delete_get)) .post(this.responseRedirectHandler(this.controller.delete)); this.router .route(\u0026#39;/menuItems/:id/update\u0026#39;) .get(this.responseHandler(this.controller.update_get)) .post( express.json(), this.responseRedirectHandler(this.controller.update) ); } } /menuItems：MenuItem 的主頁面 '/menuItems/:id'：讀取指定 ID 的 MenuItem '/menuItems/create'：新增 '/menuItems/update'：更新 '/menuItems/delete'：刪除 MenuItem Controller 接著開始實作各個路由的功能，到 main/menu/menuItem.controller.ts。\n前置 import { MenuItem } from \u0026#39;@prisma/client\u0026#39;; import { Request } from \u0026#39;express\u0026#39;; import { ControllerBase } from \u0026#39;../../base/controller.base\u0026#39;; import { MenuItemService } from \u0026#39;./menuItem.service\u0026#39;; export class MenuItemController extends ControllerBase { private readonly menuService = new MenuItemService(); // 實作的其他功能 } menuService：Controller 會把資料傳給 Service，並等待 Service 傳回從 Database 讀取來的資料 有些功能會在開始執行前，會先確定該筆資料是否存在於資料庫，如果沒有就會出現錯誤，所以掌握錯誤就很重要。建立一個檢查從資料庫回傳回來的資料是否為空的，如果是空的那就顯示錯誤的資訊：\nprivate checkMenuItem = async (id: string, menuItem: MenuItem | null) =\u0026gt; { if (menuItem === null) { return this.formatResponse(\u0026#39;error\u0026#39;, { error: new Error(`MenuItem ${id} is not exist`), }); } else { return menuItem; } }; Create public async form() { return this.formatResponse(\u0026#39;menuItem_form\u0026#39;); } public async create(req: Request) { const { name, description, price } = req.body; const menuItem = await this.menuService.create(name, description, price); return this.formatRedirectResponse(`/menuItems/${menuItem.id}`); } Read one public async get(req: Request) { const { id } = req.params; const menuItem = await this.menuService.get(Number(id)); this.checkMenuItem(id, menuItem); return this.formatResponse(\u0026#39;menuItem_detail\u0026#39;, { menuItem: menuItem }); } Read many public async get_many(req: Request) { const skip = req.query.skip || 0; const take = req.query.take || 10; const menuItems = await this.menuService.get_many( Number(skip), Number(take) ); return this.formatResponse(\u0026#39;menuItem\u0026#39;, { menuItems: menuItems, }); } Update public async update_get(req: Request) { const { id } = req.params; const menuItem = await this.menuService.get(Number(id)); this.checkMenuItem(id, menuItem); return this.formatResponse(\u0026#39;menuItem_form\u0026#39;, { data: menuItem }); } public async update(req: Request) { const { id } = req.params; const { name, description, price } = req.body; const menuItem = await this.menuService.update(Number(id), { name: name, description: description, price: Number(price), }); return this.formatRedirectResponse(`/menuItems/${menuItem.id}`); } Delete public async delete_get(req: Request) { const { id } = req.params; const deleteUrl = req.path.split(\u0026#39;/\u0026#39;)[1]; const menuItem = await this.menuService.get(Number(id)); this.checkMenuItem(id, menuItem); return this.formatResponse(\u0026#39;delete\u0026#39;, { deleteItem: menuItem, deleteUrl: deleteUrl, }); } public async delete(req: Request) { const { id } = req.params; await this.menuService.delete(Number(id)); return this.formatRedirectResponse(\u0026#39;/menuItems\u0026#39;); } MenuItem Views View 的部分就很簡單，只要把後端傳來的資料依據自己喜歡的方式放置即可，如需要參考可以到 et860525/restaurant-management/views。\n結語 整個專案到這裡就告一段落了，剩下的其他 table 的功能基本上建立的方式都大致相同。這樣用 OOP 方式分開各個元件有幾個好處：\n專責分類：根據功用分開才不會讓單一支程式負擔太大 清楚標示：分類後就能知道哪一個元件做哪一件事情，就不會 controller 還要獲得資料庫資料 測試方便：可以對單一個元件進行測試 ","permalink":"https://et860525.github.io/posts/restaurant-management-modify-base-code/","summary":"\u003cp\u003e當我開始完善各個功能時，就發現回傳 view 所需要的函式不只有 \u003ccode\u003erender\u003c/code\u003e，在某些時候還是要使用 \u003ccode\u003eredirect\u003c/code\u003e，而當這樣會有兩種格式要回傳時，我就會建立 \u003cstrong\u003eResponse Object\u003c/strong\u003e 來制定回傳的格式，並且在 \u003ccode\u003eroute.base\u003c/code\u003e 中就要多一個專門處理 \u003ccode\u003eredirect\u003c/code\u003e 的函式。\u003c/p\u003e\n\u003cp\u003e當這些都完成後，就可以開始實作網頁的功能了，在這篇文章裡我會實作 \u003ccode\u003eMenuItem\u003c/code\u003e 的 CRUD。\u003c/p\u003e\n\u003cp\u003eGithub：\u003ca href=\"https://github.com/et860525/restaurant-management\"\u003eet860525/restaurant-management\u003c/a\u003e\u003c/p\u003e","title":"Restaurant Management 專案(三) - 新增 Response Object 與完成 MenuItem"},{"content":"接下來就要設計 Model 與建立 Repository 來跟資料庫進行交互。\n首先，設計 Model 的範本是來自 Cheseto Restaurant POS App - Full Preview，此範本包含四個 table：\nTable：餐廳裡的桌子 MenuItem：菜單品項 Order：訂單 Customer：客人的資訊 完成 Model 後，先寫出 repository.base 再套用到各自的 table 上，以上。\nGithub：et860525/restaurant-management\n設計 Model 以上資料庫的重點為：\n一個顧客 (Customer) 可以有多張訂單 (Order) 一張桌子 (Table) 可以有多張訂單 (Order) 訂單 (Order) 與 菜單品項 (MenuItem) 是多對多 (many-to-many) 的關係，而這裡使用 Explicit many-to-many relations，原因是我想將菜單品項的數量放在裡面 以下是 Prisma 的程式碼：\ngenerator client { provider = \u0026#34;prisma-client-js\u0026#34; } datasource db { provider = \u0026#34;postgresql\u0026#34; url = env(\u0026#34;DATABASE_URL\u0026#34;) } model Customer { id Int @id @default(autoincrement()) name String phone String email String @unique address String orders Order[] } model MenuItem { id Int @id @default(autoincrement()) name String description String? price Float orders OrderItem[] } model Order { id Int @id @default(autoincrement()) customer Customer @relation(fields: [customerId], references: [id]) customerId Int table Table @relation(fields: [tableId], references: [id]) tableId Int items OrderItem[] tag String @default(dbgenerated(\u0026#34;lpad(nextval(\u0026#39;order_tag_seq\u0026#39;)::text, 6, \u0026#39;0\u0026#39;)\u0026#34;)) status Order_status @default(PLACED) payment_method Payment @default(Cash) createdAt DateTime @default(now()) } model OrderItem { order Order @relation(fields: [orderId], references: [id]) orderId Int menuItem MenuItem @relation(fields: [menuItemId], references: [id]) menuItemId Int quantity Int @@id([orderId, menuItemId]) } model Table { id Int @id @default(autoincrement()) number Int capacity Int status Table_status @default(Free) orders Order[] } enum Order_status { PLACED IN_PROGRESS COMPLETED CANCELLED } enum Table_status { Free Checked_in Reserved } enum Payment { Cash Debit E_wallet } 首先要注意的是 Order 裡面的 tag 欄位，它的作用是將 tag 顯示成 000001。 @default(dbgenerated(\u0026quot;lpad(nextval('order_tag_seq')::text, 6, '0')\u0026quot;))：\ndbgenerated()：表示有些功能沒辦法再 Primsa 使用，但是在資料庫裡可以 lpad(string, length[, fill])：將指定字串的左邊填充指定字串到指定長度 nextval：根據 Sequences 的 INCREMENT 來獲得下一個值 由於 order_tag_seq 它的欄位型別是 SEQUENCE，但是在 Primsa 是無法加入這個型別的欄位，所以這裡必須要先將 migrate 檔案產生出來後，再來改裡面的 SQL 語法。其步驟為：\n先輸入 prisma migrate dev --create-only ( 參考來源 Customizing migrations ) 到剛剛產生的 migrate 檔案 (prisma/migrations/20230310190516_test/migration.sql) 下新增 CREATE SEQUENCE order_tag_seq START 1; 再使用 prisma migrate dev 即可完成 如果沒有上面的步驟，而是直接 migrate 就會出現錯誤，因為找不到 order_tag_seq 這個欄位。\nRepository 如果是使用 Mongoose 的專案，為了滿足Layered Architecture 就要先建立一個 Repository 來存放與資料庫交互的程式碼，再由需要資料庫資料的相關程式碼來呼叫，如：Service。但在 Prisma 裡就會比較簡單，這是因為 Prisma Client 本身就是一個 Object 直接使用即可，相關的資料格式可以在 Service 檔案裡做調整。\n嘗試寫一個 Repository Base 在使用 Prisma Client 時，我一直在嘗試讓程式碼更簡潔。因為我有四個 tables 就要建立四個 Repository 的檔案，我有想過讓每一個 table 都繼承一個 Repository Base 物件，並讓這個 Repository Base 直接實作所有獲取資料的方式，以下只是思考的程式碼並不能執行：\nimport { PrismaClient, MenuItem, Order, Customer, Table } from \u0026#39;@prisma/client\u0026#39;; export abstract class RepositoryBase { protected modelName: string = \u0026#39;\u0026#39;; private prisma = new PrismaClient(); public async get(id: number): Promise\u0026lt;MenuItem | Order | Customer | Table | null\u0026gt; { return await this.[modelName].findUnique({ where: { id: id }, }) } } 雖然這個樣子可以少寫程式碼，但是在有些 table 有 relations 時，可能就會需要使用到 include。如果是在 create 的情況下，就要在相應的 Repository 下重寫整個 create 程式碼，那這樣還不如就直接根據相對應的 table，來寫相對應的程式碼就好了。\n我有試過使用 switch，但是那個可讀性還不如寫在各自的 Repository 檔案裡\n實作 上面有說到，直接使用 Prisma Client 物件就可以了，所以這裡我會直接在 Service 檔案裡直接使用 Prisma Client：\nimport { Prisma, PrismaClient, MenuItem } from \u0026#39;@prisma/client\u0026#39;; export class MenuItemService { private readonly prisma = new PrismaClient(); public async get(id: number): Promise\u0026lt;MenuItem | null\u0026gt; { return await this.prisma.menuItem.findUnique({ where: { id: id }, }); } public async get_many( skip: number, take: number ): Promise\u0026lt;MenuItem[] | null\u0026gt; { return await this.prisma.menuItem.findMany({ skip: skip, take: take, }); } public async create( name: string, description: string, price: string ): Promise\u0026lt;MenuItem\u0026gt; { return await this.prisma.menuItem.create({ data: { name: name, description: description, price: Number(price), }, }); } public async delete(id: number): Promise\u0026lt;MenuItem\u0026gt; { return await this.prisma.menuItem.delete({ where: { id: id }, }); } } Controller 會將獲得的參數 ( req 或 Controller 本身的參數 ) 送到 Service 裡，Service 會使用 Prisma Client 來跟資料庫交互，最後獲得的結果再回傳給 Controller。\n目前我只完成 MenuItem table，後面三個參數我會慢慢完成，完成後，就會開始把前端的部分完成\n結語 因為官網文件很完整，所以設計 Model 的部分就沒有那麼多的問題。但是在設計 Repository 的部分就卡的比較久一點，就像上面嘗試的部分撰寫的一樣，我一直很想少寫這些近乎重複的程式碼，但也就是這些微的不同就會影響資料顯示的不同，但我還是想先把它們都寫出來後，再來慢慢的修改。\n","permalink":"https://et860525.github.io/posts/restaurant-management-model-repository/","summary":"\u003cp\u003e接下來就要設計 \u003ccode\u003eModel\u003c/code\u003e 與建立 \u003ccode\u003eRepository\u003c/code\u003e 來跟資料庫進行交互。\u003c/p\u003e\n\u003cp\u003e首先，設計 \u003ccode\u003eModel\u003c/code\u003e 的範本是來自 \u003ca href=\"https://dribbble.com/shots/20762377-Cheseto-Restaurant-POS-App-Full-Preview\"\u003eCheseto Restaurant POS App - Full Preview\u003c/a\u003e，此範本包含四個 table：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eTable\u003c/strong\u003e：餐廳裡的桌子\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMenuItem\u003c/strong\u003e：菜單品項\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOrder\u003c/strong\u003e：訂單\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCustomer\u003c/strong\u003e：客人的資訊\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e完成 \u003ccode\u003eModel\u003c/code\u003e 後，先寫出 \u003ccode\u003erepository.base\u003c/code\u003e 再套用到各自的 table 上，以上。\u003c/p\u003e\n\u003cp\u003eGithub：\u003ca href=\"https://github.com/et860525/restaurant-management\"\u003eet860525/restaurant-management\u003c/a\u003e\u003c/p\u003e","title":"Restaurant Management 專案(二) - 建立 Model 與 Repository"},{"content":"這個專案會使用 OOP 的方式來建構，前端部分會以簡單的方式呈現。\n整個架構會用到的重要套件：\nPackage Usage Express Web 應用框架 TypeScript 開發工具 Prisma 訪問資料庫 Docker 應用容器化 PostgreSQL 資料庫 此專案的目的是要讓 Express 使用 Prisma 來訪問資料庫，並且使用 Docker 來建立 PostgreSQL 資料庫。\nGithub：et860525/restaurant-management\n專案架構 整個專案的架構大致會遵循 et860525/express-project-architecture。\n最大的不同就是資料庫的部分，因為這一個專案使用的是 Prisma，所以我不需要先做連接資料庫的動作。建立 model 的地方會改成 prisma/schema.prisma。\n這裡我會先建立一個簡單的 model 來做測試：\ngenerator client { provider = \u0026#34;prisma-client-js\u0026#34; } datasource db { provider = \u0026#34;postgresql\u0026#34; url = env(\u0026#34;DATABASE_URL\u0026#34;) } model Restaurant { id Int @id @default(autoincrement()) name String address String? phone String? createdAt DateTime @default(now()) updatedAt DateTime @updatedAt } 完成後使用 pnpx prisma migrate dev --name init 來將 model migrate 進資料庫。\n訪問資料庫 將資料庫部屬在 Docker 裡，輸入 docker compose up -d。因為我有在設定裡寫 restart: always，所以第一次部屬後，往後只要重新運行 Docker 就會自動啟動。\nPrisma 提供 Prisma Client 來訪問資料庫進而獲取資料。\n我把訪問資料庫的程式碼寫在 src/repositories/restaurant.repository.ts：\nimport { PrismaClient } from \u0026#39;@prisma/client\u0026#39;; export class RestaurantRepository { private prisma = new PrismaClient(); public async addRestaurant(name: string, address: string, phone: string) { const result = await this.prisma.restaurant.create({ data: { name, address, phone, }, }); return result; } public async getRestaurant(id: string) { const restaurant = await this.prisma.restaurant.findUnique({ where: { id: Number(id), }, }); return restaurant; } public async getRestaurants(skip: number = 0, take: number = 10) { const take_og = 10; const restaurants = await this.prisma.restaurant.findMany({ skip: skip, take: Math.min(take, take_og), }); return restaurants; } } 這裡很多東西都沒有寫得很完整，像是回傳型別、命名有冗詞之類的，不過目前只是為了方便測試我就沒有寫得太詳細，往後會寫的更加完整。\nController 與 Route 通常只要能把訪問資料庫的部分做出來，在 Controller 與 Route 的部分我覺得就比較輕鬆了。不過這跟上一個 API 專案不同，這次有用到 view 來顯示前端，所以我必須要先更改 src/base/controller.base.ts 與 src/base/route.base.ts：\nsrc/base/route.base.ts import { Router, Request, Response, NextFunction } from \u0026#39;express\u0026#39;; import { ControllerBase } from \u0026#39;./controller.base\u0026#39;; export abstract class RouteBase { public router: Router = Router(); protected controller!: ControllerBase; constructor() { this.initial(); } protected initial(): void { this.registerRoute(); } protected abstract registerRoute(): void; protected responseHandler( method: (req: Request, res: Response, next: NextFunction) =\u0026gt; Promise\u0026lt;any\u0026gt; ) { return (req: Request, res: Response, next: NextFunction) =\u0026gt; { method .call(this.controller, req, res, next) .then((obj) =\u0026gt; res.render(obj.template, obj.data)) .catch((err) =\u0026gt; next(err)); }; } } responseHandler 會呼叫 controller 丟進去的 method，當他完成後會回傳 template 的名字與 template 要使用的資料。 src/base/controller.base.ts export abstract class ControllerBase { public formatResponse(template: string, data?: any) { const responseObject = { template: template, data: data }; return responseObject; } } 只需要將 template 的名字與給 template 使用的資料丟回即可。 實做 src/main/restaurant/restaurant.controller.ts import { Request } from \u0026#39;express\u0026#39;; import { ControllerBase } from \u0026#39;../../base/controller.base\u0026#39;; import { RestaurantRepository } from \u0026#39;../../repositories/restaurant.repository\u0026#39;; export class RestaurantController extends ControllerBase { private readonly restaurantRepo = new RestaurantRepository(); public async addRestaurant_get() { return this.formatResponse(\u0026#39;restaurant_form\u0026#39;); } public async addRestaurant(req: Request) { const { name, address, phone } = req.body; console.log(req.body); const result = await this.restaurantRepo.addRestaurant( name, address, phone ); console.log(result); return this.formatResponse(\u0026#39;restaurant_form\u0026#39;, { result: result }); } public async getRestaurant(req: Request) { const { id } = req.params; const restaurant = await this.restaurantRepo.getRestaurant(id); return this.formatResponse(\u0026#39;restaurant\u0026#39;, { restaurant: restaurant }); } public async getRestaurants(req: Request) { const skip = req.query.skip || 0; const take = req.query.take || 10; const restaurants = await this.restaurantRepo.getRestaurants( Number(skip), Number(take) ); return this.formatResponse(\u0026#39;restaurant_list\u0026#39;, { restaurants: restaurants, }); } } src/main/restaurant/restaurant.routing.ts import express, { Request, Response, NextFunction } from \u0026#39;express\u0026#39;; import { RouteBase } from \u0026#39;../../base/route.base\u0026#39;; import { RestaurantController } from \u0026#39;./restaurant.controller\u0026#39;; export class RestaurantRoute extends RouteBase { protected controller!: RestaurantController; constructor() { super(); } protected initial(): void { this.controller = new RestaurantController(); super.initial(); } protected registerRoute(): void { this.router.get(\u0026#39;/\u0026#39;, (req: Request, res: Response, next: NextFunction) =\u0026gt; { res.render(\u0026#39;index\u0026#39;); }); this.router.get( \u0026#39;/restaurant\u0026#39;, this.responseHandler(this.controller.getRestaurants) ); this.router .route(\u0026#39;/restaurant/create\u0026#39;) .get(this.responseHandler(this.controller.addRestaurant_get)) .post( express.json(), this.responseHandler(this.controller.addRestaurant) ); this.router.get( \u0026#39;/restaurant/:id\u0026#39;, this.responseHandler(this.controller.getRestaurant) ); } } 目前只有實作：\n新增 (add) GET 顯示表格 POST 新增資料 單個查詢 (getRestaurant) 多個查詢 (getRestaurants) 這樣整個測試的專案就完成了。\n結語 我是第一次使用 Prisma 來訪問資料庫，以前都是使用 Mongoose ODM 來操作資料庫的部分。\n接下來我會開始將專案改成實際使用狀態，所以現在的 model 我還會再做修改。\n","permalink":"https://et860525.github.io/posts/restaurant-management-init/","summary":"\u003cp\u003e這個專案會使用 OOP 的方式來建構，前端部分會以簡單的方式呈現。\u003c/p\u003e\n\u003cp\u003e整個架構會用到的重要套件：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003ePackage\u003c/th\u003e\n\u003cth\u003eUsage\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://expressjs.com/\"\u003eExpress\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eWeb 應用框架\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://www.typescriptlang.org/\"\u003eTypeScript\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e開發工具\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://www.prisma.io/\"\u003ePrisma\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e訪問資料庫\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://www.docker.com/\"\u003eDocker\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e應用容器化\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://www.postgresql.org/\"\u003ePostgreSQL\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e資料庫\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e此專案的目的是要讓 Express 使用 Prisma 來訪問資料庫，並且使用 Docker 來建立 PostgreSQL 資料庫。\u003c/p\u003e\n\u003cp\u003eGithub：\u003ca href=\"https://github.com/et860525/restaurant-management\"\u003eet860525/restaurant-management\u003c/a\u003e\u003c/p\u003e","title":"Restaurant Management 專案(一) - 架構與初始化"},{"content":"使用 Docker 來建置 MongoDB，可以先到 docker mongo 來選擇版本。\nMongoDB 會有幾種架構：\nStandalone 建立難度 低 單一 MongoDB 資料庫 Replica Set 建立難度 中 資料會有多個副本提供容錯空間 Sharded Cluster 建立難度 高 資料放置在不同的 shard，每個 shard 或 config servers 都是 Replica Set Standalone Standalone 表示只有一個 MongoDB 實體，Mongo Client 只要直接連接它就可以使用。\n根據 Docker compose file 所顯示，2023年六月後就不會支援 Compose V1 ，所以除了在 Standalone 會試做一個 V1，其他都會換成 Compose V2 的格式\nDocker compose V1 使用 docker-compose 來建立 MongoDB：\n# docker-compose.yml versio: \u0026#39;3.1\u0026#39; services: mongo: image: mongo:latest container_name: mongodb environment: MONGO_INITDB_ROOT_USERNAME: root MONGO_INITDB_ROOT_PASSWORD: example ports: - \u0026#39;27017:27017\u0026#39; volumes: - mongo-mount-data:/data/db 運行 docker-compose：\n# Start docker-compose up -d # Close docker-compose down Docker compose V2 # docker-compose.yaml services: mongo: image: mongo:latest container_name: mongodb-test environment: MONGO_INITDB_ROOT_USERNAME: root MONGO_INITDB_ROOT_PASSWORD: example ports: - \u0026#39;27017:27017\u0026#39; volumes: - mongo-mount-data:/data/db 運行 docker compose：\n# Start docker compose up -d # Close docker compose down 進入 mongoDB docker exec -it \u0026lt;mongo-name\u0026gt; bash 輸入後會看到命令列會由 root 開頭，接著再輸入：\n# 5.0+ mongosh -u root -p # 4.0 mongo -u root -p 輸入密碼後，就可以進入 MongoDB 了。\n使用 VM 會遇到的問題 如果在 VM 下使用 MongoDB 5.0+ 以上的版本，有可能會看到：\nWARNING: MongoDB 5.0+ requires a CPU with AVX support, and your current system does not appear to have that! 根據 Mongo DB deployment not working in kubernetes because processor doesn\u0026rsquo;t have AVX support\n如果是 Windows + VirtualBox 可以在 CMD 輸入：\nbcdedit /set hypervisorlaunchtype off DISM /Online /Disable-Feature:Microsoft-Hyper-V 重開機後就可以解決。\n目前我這裡還是有使用 WSL2，如果輸入以上指令可能會造成 WSL2 無法使用，所以我選擇使用舊版本，暫且不使用 mongo:5.0+。\nReplica Set MongoDB Replication 可以建立一份資料庫副本，在主要的資料庫發生問題時，副本可以直接接手主要資料庫的工作。\n使用 Replica Set 的重點：\nReplica Set 會提供 High availability 依照硬體規格來調整 Replica Set，例如：更大更快的硬碟 不會影響 Primary，使用 Read Preference 來讀取更快更近的副本 MongoDB Replication 的架構 MongoDB Replication 主要的架構的構成：\nReplica Set Member 有兩種：\nPrimary：接受所有讀寫的操作 Secondaries：複製 Primary 的資料 最基本的 Replica Set 需要有三個數據承載成員 ( data-bearing members )：一個 Primary 與二個 Secondary：\n在某些情況下 ( 例如：硬體限制 ) 可以將某個 member 改為 arbiter，它只會參與 投票 ( elections ) 並不會擁有任何資料，更不會成為 Primary：\n以下使用 Docker compose 來建構 Replica Set。\nDocker compose 使用 Docker compose 來建立下方的架構：\n這一個 Replica Set 命名為 RS，需要使用 --replSet RS 建立三個 container 來滿足最基本的 Replica Set： container (rs1/rs2/rs3) ；port ( 27041/27042/27043) docker-compose-replica-set.yaml：\nservices: rs1: image: mongo:4.4.19-focal container_name: rs1 network_mode: host command: mongod --replSet RS --port 27041 --dbpath /data/db --config /resource/mongod.yaml volumes: - ./replica/config/mongod.yaml:/resource/mongod.yaml - ./replica/data/rs1:/data/db extra_hosts: - \u0026#34;rs1.local:127.0.0.1\u0026#34; - \u0026#34;rs2.local:127.0.0.1\u0026#34; - \u0026#34;rs3.local:127.0.0.1\u0026#34; rs2: image: mongo:4.4.19-focal container_name: rs2 network_mode: host command: mongod --replSet RS --port 27042 --dbpath /data/db --config /resource/mongod.yaml volumes: - ./replica/config/mongod.yaml:/resource/mongod.yaml - ./replica/data/rs2:/data/db extra_hosts: - \u0026#34;rs1.local:127.0.0.1\u0026#34; - \u0026#34;rs2.local:127.0.0.1\u0026#34; - \u0026#34;rs3.local:127.0.0.1\u0026#34; rs3: image: mongo:4.4.19-focal container_name: rs3 network_mode: host command: mongod --replSet RS --port 27043 --dbpath /data/db --config /resource/mongod.yaml volumes: - ./replica/config/mongod.yaml:/resource/mongod.yaml - ./replica/data/rs3:/data/db extra_hosts: - \u0026#34;rs1.local:127.0.0.1\u0026#34; - \u0026#34;rs2.local:127.0.0.1\u0026#34; - \u0026#34;rs3.local:127.0.0.1\u0026#34; network_mode 設定為 host，資料庫會如同架設在本機一樣，讓 rs1.local、rs2.local 與 rs3.local 都會對應到 127.0.0.1 command 裡面的設定： --dbpath：指定 MongoDB 存放資料的資料夾 --port：指定 MongoDB 要開啟的 Port --config：指定 MongoDB Config file volumes 裡面的設定： ./replica/config/mongod.yaml:/resource/mongod.yaml：其格式為 A:B，A 為主機端的路徑；B 為容器內的路徑。當容器掛載完成，容器端就會有 /resource/mongod.yaml 檔案，達到路徑能共享資料的功能 ./replica/data/rs3:/data/db：與上方設定很像，資料共享與綁定。當目前的容器被刪除後，其資料都會被存放在本機端，等待下一個容器指向相同的位置，就可以繼續使用以前的資料 extra_hosts 設定解析的域名 rs1.local、rs2.local 與 rs3.local 都會解析 127.0.0.1，這樣就不用再打 127.0.0.1 接下來設定 MongoDB config file replica/config/mongod.yaml：\nnet: bindIpAll: true storage: engine: wiredTiger wiredTiger: engineConfig: cacheSizeGB: 0.1 net Option 裡的 bindIpAll：設定那些 Client IP 可以連進 MongoDB，預設為 localhost 也就是只有本機。假設 Client IP 來自不同的主機，設定 true 就表示任何 Client IP 都可以連進來 storage Option 裡的 engine：有 wiredTiger 與 inMemory 兩種，不論選擇哪一個都要小心設定 cacheSizeGB 或 inMemorySizeGB 的大小。這是因為 Mongo 會依照硬體配置來計算內部緩存的預設值，而 Mongo 並不會知道自己運行在 Docker 容器中，所以在同一個 Docker 上架設兩台以上的 Mongo，就有可能會出現問題，如：斷線或無法連線進去。所以使用 Docker 架設 Mongo 一定要設定 以上只用使用幾個重要的設定，完整的 Mongo config 可以到 Configuration File Options。\n都完成後，使用 docker compose up -d 來運行。\nReplica Set 設定 確認資料庫連線狀況 進入 rs1 容器，來測試能否用域名連線到其他資料庫：\ndocker exec -it rs1 bash 確認資料庫連線：\nmongo rs1.local:27041 --eval \u0026#34;print(\u0026#39;rs1 ok\u0026#39;)\u0026#34; mongo rs2.local:27042 --eval \u0026#34;print(\u0026#39;rs2 ok\u0026#39;)\u0026#34; mongo rs3.local:27043 --eval \u0026#34;print(\u0026#39;rs3 ok\u0026#39;)\u0026#34; 如果都能顯示這些字串，就可以開始設定 Replica Set。\n設定 Replica Set 隨便進入一個 member：\nmongo rs1.local:27041 設定 Replica Set config：\ncfg = { \u0026#34;_id\u0026#34;: \u0026#34;RS\u0026#34;, \u0026#34;members\u0026#34;: [{ \u0026#34;_id\u0026#34;: 0, \u0026#34;host\u0026#34;: \u0026#34;rs1.local:27041\u0026#34; }, { \u0026#34;_id\u0026#34;: 1, \u0026#34;host\u0026#34;: \u0026#34;rs2.local:27042\u0026#34; }, { \u0026#34;_id\u0026#34;: 2, \u0026#34;host\u0026#34;: \u0026#34;rs3.local:27043\u0026#34; } ] }; rs.initiate(cfg); 顯示 ok: 1 就表示完成。\n確認 Replica Set 狀態 當要增加或減少 member 時，或是要檢查 member 是否有連線，就要確認 member 的狀態。最常用的有三種：\nrs.status()：members 的狀態 rs.status().members.forEach(m =\u0026gt; print(`${m.name} =\u0026gt; ${m.stateStr}`)) 會列出： rs1.local:27041 =\u0026gt; PRIMARY rs2.local:27042 =\u0026gt; SECONDARY rs3.local:27043 =\u0026gt; SECONDARY 當然也可以直接使用 rs.status() 來看更詳細的狀態。 rs.printSecondaryReplicationInfo()：members 的同步狀態 source: rs2.local:27042 syncedTo: Fri Mar 03 2023 11:50:04 GMT+0000 (UTC) 0 secs (0 hrs) behind the primary source: rs3.local:27043 syncedTo: Fri Mar 03 2023 11:50:04 GMT+0000 (UTC) 0 secs (0 hrs) behind the primary rs.printReplicationInfo()：members 的 oplog 狀態 configured oplog size: 6040.000781059265MB log length start to end: 18735secs (5.2hrs) oplog first event time: Fri Mar 03 2023 06:33:09 GMT+0000 (UTC) oplog last event time: Fri Mar 03 2023 11:45:24 GMT+0000 (UTC) now: Fri Mar 03 2023 11:45:31 GMT+0000 (UTC) 結語 起初會接觸到 Replica Set 的原因，是出自於我想使用 Prisma 連接 local MongoDB。不過當連接時就會跳出錯誤：\nprisma needs to perform transactions, which requires your mongodb server to be run as a replica set. 這也讓我想了解一下這個 Replica Set 到底是什麼東西。\n而看了該文章才知道，在 Docker 裡建立 MongoDB 時需要設定 cacheSizeGB 來設定緩存大小。可能是通常我也只會使用到一個的 MongoDB 資料庫，所以才沒有遇到那些問題。\nReference [資料庫]使用 Docker 構築不同 MongoDB 架構 (三) - Replica Set ","permalink":"https://et860525.github.io/posts/docker-mongodb/","summary":"\u003cp\u003e使用 Docker 來建置 MongoDB，可以先到 \u003ca href=\"https://hub.docker.com/_/mongo\"\u003edocker mongo\u003c/a\u003e 來選擇版本。\u003c/p\u003e\n\u003cp\u003eMongoDB 會有幾種架構：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eStandalone\n\u003cul\u003e\n\u003cli\u003e建立難度 \u003cstrong\u003e低\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e單一 MongoDB 資料庫\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.mongodb.com/docs/manual/replication/\"\u003eReplica Set\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e建立難度 \u003cstrong\u003e中\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e資料會有多個副本提供容錯空間\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.mongodb.com/docs/manual/sharding/\"\u003eSharded Cluster\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e建立難度 \u003cstrong\u003e高\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e資料放置在不同的 shard，每個 shard 或 config servers 都是 \u003ccode\u003eReplica Set\u003c/code\u003e\n\u003cimg loading=\"lazy\" src=\"/images/Docker-mongodb/Docker-sharded-cluster-production-architecture.png\" alt=\"Docker-sharded-cluster-production-architecture.png\"  /\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e","title":"Docker: 設定 MongoDB"},{"content":"Pnpm ( Performant Node Package Manager ) 是一個套件管理器。根據官網表示，可以節省磁碟空間並提升安裝速度。\nFast, disk space efficient package manager\npnpm 的特點 不同的專案共用依賴套件，節省磁碟空間 所有依賴套件的檔案都會被存在同一個位置中，當有專案需要依賴套件時，它的檔案會被硬連結到該位置，這樣就不會消耗額外的磁碟空間\n非扁平化的 node_modules 目錄 npm 與 yarn 都是以扁平化的方式建立 node_modules 目錄，他們會產生非法訪問依賴的問題。舉個例子，今天有 A、B 和 C 三種套件，而他們之中的關係是 A 依賴 C 的 API，如果 B 版本更新並依賴 C 的 2.0.1 版本，但 A 依然還是使用舊版的 C，那就會報錯。\n而 pnpm 是使用軟連結的方式來建構 node_modules 目錄：\n當開發者安裝套件 bar@1.0.0，而 bar@1.0.0 又依賴 foo@1.0.0套件，此時 pnpm 就會將專案直接依賴的套件硬連結於 .pnpm store。而 bar@1.0.0 的 foo@1.0.0 就會使用軟連結直接依賴的 foo@1.0.0。\n這樣就可以避免非法訪問依賴的問題了。\n更多與 npm/yarn 的比較 Feature Comparison\n安裝方式 我使用的是 Linux 系統，根據官網的文件下載：\n# bash wget -qO- https://get.pnpm.io/install.sh | ENV=\u0026#34;$HOME/.bashrc\u0026#34; SHELL=\u0026#34;$(which bash)\u0026#34; bash - 其他下載方式：pnpm Installation\nCommands npm command pnpm equivalent npm init pnpm init npm install pnpm install npm i \u0026lt;pkg\u0026gt; pnpm add \u0026lt;pkg\u0026gt; npm run \u0026lt;cmd\u0026gt; pnpm \u0026lt;cmd\u0026gt; pnpm update：如果沒有加上 --filter 來指定 package，那就是更新全部 pnpm remove：也可以使用 rm, uninstall, un 更多的指令可以參考官網的 CLI commands。\n結論 最近開始轉成使用 pnpm，有感的就是速度很快。會使用它最大的原因就是它能將依賴件都放在同一資料夾管理 (專案裡的.pnpm)，這樣就不會因為不同的依賴件版本，造成其他依賴件錯誤的問題。\nSource pnpm, Fast, disk space efficient package manager 为什么现在我更推荐 pnpm 而不是 npm/yarn? ","permalink":"https://et860525.github.io/posts/pnpm/","summary":"\u003cp\u003e\u003ca href=\"https://pnpm.io/\"\u003ePnpm\u003c/a\u003e ( Performant Node Package Manager ) 是一個套件管理器。根據官網表示，可以節省磁碟空間並提升安裝速度。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eFast, disk space efficient package manager\u003c/p\u003e\n\u003c/blockquote\u003e","title":"Pnpm ( Performant Node Package Manager )"},{"content":"生命週期 ( lifetimes ) 會確保我們在需要引用的時候，它們都是有效的。\n在 Rust 中，每個引用都是有生命週期的，簡單來說就是它的有效範圍。在大多情況下，生命週期都是隱藏且可以推導出來的，如同型別一樣也都是可以推導出來的。當型別有很多種可能的情況下，就要詮釋型別，同樣在生命週期下，引用以不同方式關聯的話，就要詮釋生命週期。\n透過生命週期預防迷途引用 生命週期最主要的目的就是要預防迷途引用 ( dangling references )：\nfn main() { let r; { let x = 5; r = \u0026amp;x; } println!(\u0026#34;r: {}\u0026#34;, r); } 在這裡嘗試使用已經離開作用域的引用，就會得到錯誤訊息，這是因為 r 所指向的數值已經離開作用域。這也表示變數 x 存在的不夠久。那 Rust 要如何決定程式碼無效？它使用了借用檢查器 ( borrow checker ) 來做檢查。\n借用檢查器 ( Borrow checker ) Rust 編譯器有一個借用檢查器 ( borrow checker ) 會比較作用域來檢測所有的借用是否有效。\n依上面的程式碼為例：\nfn main() { let r; // ---------+-- \u0026#39;a // | { // | let x = 5; // -+-- \u0026#39;b | r = \u0026amp;x; // | | } // -+ | // | println!(\u0026#34;r: {}\u0026#34;, r); // | } // ---------+ r 的生命週期為 'a，x 為 'b，可以看到 'b 的生命週期區塊比 'a 還要小。而 r 引用了一個生命週期比他自己還短的變數 x，所以程式會報錯：引用的對象比引用者存在的時間還短。\n以下為修正版本：\nfn main() { let x = 5; // ----------+-- \u0026#39;b // | let r = \u0026amp;x; // --+-- \u0026#39;a | // | | println!(\u0026#34;r: {}\u0026#34;, r); // | | // --+ | } // ----------+ 此時 x 的生命週期 'b 比 r 的生命週期 'a 還長，Rust 就能知道 r 引用 x 是永遠有效的。\n函式中的泛型生命週期 寫一個比較兩個字串切片誰比較長的函式。該函式會接收兩個字串切片並回傳一個字串切片：\nfn main() { let string1 = String::from(\u0026#34;abcd\u0026#34;); let string2 = \u0026#34;xyz\u0026#34;; let result = longest(string1.as_str(), string2); println!(\u0026#34;The longest string is {}\u0026#34;, result); } 該函式接收的是字串切片的引用，而不是字串，因此我們不希望 longest 拿到參數的所有權。\n字串切片本來就是引用，所以作為參數時可以不用加入 \u0026amp;\n實作 longest 函式：\nfn longest(x: \u0026amp;str, y: \u0026amp;str) -\u0026gt; \u0026amp;str { if x.len() \u0026gt; y.len() { x } else { y } } 編譯後會出現生命週期的錯誤：\n$ cargo run Compiling chapter10 v0.1.0 (file:///projects/hello) error[E0106]: missing lifetime specifier --\u0026gt; src/main.rs:9:33 | 9 | fn longest(x: \u0026amp;str, y: \u0026amp;str) -\u0026gt; \u0026amp;str { | ---- ---- ^ expected named lifetime parameter | = help: this function\u0026#39;s return type contains a borrowed value, but the signature does not say whether it is borrowed from `x` or `y` help: consider introducing a named lifetime parameter | 9 | fn longest\u0026lt;\u0026#39;a\u0026gt;(x: \u0026amp;\u0026#39;a str, y: \u0026amp;\u0026#39;a str) -\u0026gt; \u0026amp;\u0026#39;a str { | ++++ ++ ++ ++ For more information about this error, try `rustc --explain E0106`. error: could not compile `chapter10` due to previous error 錯誤訊息表示回傳型別必須要有一個泛型生命週期參數，因為 Rust 不知道回傳的引用是 x 還是 y。事實上我們也不知道，因為這裡是交由 if else 區塊判定 x 和 y 哪個字串大就回傳哪個。\n當我們不知道哪個字串會被回傳，也不知道傳遞進來的引用實際的生命週期為何，就會造成以上的問題。為了解決這個錯誤，必須要加上泛型生命週期參數來定義引用的關係，讓借用檢查器能夠分析。\n生命週期詮釋語法 生命週期詮釋 ( Lifetime Annotation ) 不會改變引用能存活多久，只是描述引用之間的相互關係，不會影響引用的生命週期。這就像函式簽名指定了一個泛型型別參數，該函式就能接受任意型別一樣。函式可以指定一個泛型生命週期參數，該函式就能接受任何生命週期。\n生命週期參數的名稱必須以 ( ' ) 作為開頭，通常是小寫且很短。大多數人都使用 'a 作為第一個生命週期詮釋。將生命週期詮釋放在 \u0026amp; 後面，再使用空格來詮釋引用的型別：\n\u0026amp;i32 // 一個引用 \u0026amp;\u0026#39;a i32 // 一個有顯式生命週期的引用 \u0026amp;\u0026#39;a mut i32 // 一個有顯式生命週期的可變引用 在函式簽名中的生命週期詮釋 在此段簽名想要表達：當所有傳遞進來的參數都是有效的，那回傳的引用才會是有效的。以下會將生命週期命名為 'a 並加進每個引用：\nfn longest\u0026lt;\u0026#39;a\u0026gt;(x: \u0026amp;\u0026#39;a str, y: \u0026amp;\u0026#39;a str) -\u0026gt; \u0026amp;\u0026#39;a str { if x.len() \u0026gt; y.len() { x } else { y } } 這樣更改完 longest 就能執行了。\n此函式簽名告訴 Rust 有個生命週期 'a，函式的兩個參數都是字串切片，並且都有生命週期 'a，而回傳的字串切片也會和生命週期 'a 存活一樣久。\n注意：當此函式簽名指定生命週期參數時，就不能變更任何傳入或傳出數值的生命週期。這個目的只是為了告訴借用檢查器一件事，拒絕任何沒有服從約束的數值。longest 函式並不需要知道 x 與 y 會存活多久，它只需要知道有某個作用域會被 'a 所取代。\n當 longest 傳入實際的引用時，泛型生命週期 'a 取得的生命週期，會等於 x 與 y 的生命週期中較短的，而回傳引用的生命週期也會相同。\n傳入不同實際生命週期的引用，來使生命週期詮釋能約束 longest 函式：\nfn main() { let string1 = String::from(\u0026#34;Long long string\u0026#34;); { let string2 = String::from(\u0026#34;xyz\u0026#34;); let result = longest(string1.as_str(), string2.as_str()); println!(\u0026#34;The longest string is {}\u0026#34;, result); } } string1 在外部作用域結束前都有效；string2 在內部作用域結束前都有效。 result 會取得某個引用直到內部作用域結束 ( 依照參數最短的生命週期 )。 接下來做一點改變，如果將 result 移動到外部作用域做宣告，並保留 result 的賦值與 string2 在內部作用域。並將使用 result 的 println! 移動到外部作用域，編譯並且觀看結果：\nfn main() { let string1 = String::from(\u0026#34;Long long string\u0026#34;); let result; { let string2 = String::from(\u0026#34;xyz\u0026#34;); result = longest(string1.as_str(), string2.as_str()); } println!(\u0026#34;The longest string is {}\u0026#34;, result); } 編譯後會看到以下的錯誤訊息：\n$ cargo run Compiling chapter10 v0.1.0 (file:///projects/hello) error[E0597]: `string2` does not live long enough --\u0026gt; src/main.rs:6:44 | 6 | result = longest(string1.as_str(), string2.as_str()); | ^^^^^^^^^^^^^^^^ borrowed value does not live long enough 7 | } | - `string2` dropped here while still borrowed 8 | println!(\u0026#34;The longest string is {}\u0026#34;, result); | ------ borrow later used here For more information about this error, try `rustc --explain E0597`. error: could not compile `chapter10` due to previous error 錯誤訊息表示，需要讓 result 與 println! 有效的話，string2 必須要在外部作用域有效，因為 Rust 知道這個函式的參數與回傳值，都使用著相同的生命週期 'a。\n當然我們都知道 string1 字串長度比較長，result 的結果會是 string1 的引用，而且 string1 還在作用域裡，照理來說應該是不會有問題才對。但是編譯器不懂，所以我們才會告訴 Rust 此函式所回傳引用的生命週期，會等於較短的生命週期。所以編譯器才會報錯，因為回傳可能會包含無效的引用。\n深入理解生命週期 再來做一點改變，如果現在 longest 回傳的條件是永遠回傳第一個字串切片，那參數 y 就可以不需要指定生命週期：\nfn longest\u0026lt;\u0026#39;a\u0026gt;(x: \u0026amp;\u0026#39;a str, y: \u0026amp;str) -\u0026gt; \u0026amp;\u0026#39;a str { x } 這是因為 x 與回傳型別的生命週期都是 'a，但現在永遠只回傳 x，y 有沒有生命週期根本沒有任何差別。這也表示當函式回傳引用時，回傳型別的生命週期必須符合其中一個參數的生命週期。所以下面的程式碼是不會編譯成功的：\nfn longest\u0026lt;\u0026#39;a\u0026gt;(x: \u0026amp;str, y: \u0026amp;str) -\u0026gt; \u0026amp;\u0026#39;a str { let result = String::from(\u0026#34;Long long string\u0026#34;); result.as_str() } 因為回傳值的生命週期與參數的生命週期無關。錯誤訊息為：\n$ cargo run Compiling chapter10 v0.1.0 (file:///projects/hello) error[E0515]: cannot return reference to local variable `result` --\u0026gt; src/main.rs:11:5 | 11 | result.as_str() | ^^^^^^^^^^^^^^^ returns a reference to data owned by the current function For more information about this error, try `rustc --explain E0515`. error: could not compile `chapter10` due to previous error 此時我們嘗試從函式中回傳 result 引用， 但 result 已經離開作用域，已經是迷途引用了，Rust 是不會允許使用迷途引用。解決這個問題最好的方法就是回傳有所有權的型別，而不是引用。\n由上可知，生命週期語法是用來連接函式中不同參數與回傳值的生命週期。只要能連結，Rust 就能有足夠的資訊防止產生迷途指標或違反記憶體安全的操作。\n在結構體中使用生命週期詮釋 結構體的所有定義都持有型別的所有權，然而結構體也可以持有引用。在這裡使用 ImportantExcerpt 來當作例子：\nstruct ImportantExcerpt\u0026lt;\u0026#39;a\u0026gt; { part: \u0026amp;\u0026#39;a str, } fn main() { let novel = String::from(\u0026#34;Call me Ishmael. Some years ago...\u0026#34;); let first_sentence = novel.split(\u0026#39;.\u0026#39;).next().expect(\u0026#34;Can not find \u0026#39;.\u0026#39;\u0026#34;); let i = ImportantExcerpt { part: first_sentence, }; } 如同泛型資料型別，在結構體名稱後加上泛型生命週期參數 ( \u0026lt;'a\u0026gt; ) 在 main 裡產生一個結構體 ImportantExcerpt 實例，變數 novel 擁有 String 資料，而 novel 在 ImportantExcerpt 實例之前建立的，這表示 novel 不會比 ImportantExcerpt 早離開作用域，所以 ImportantExcerpt 裡的引用就能成立 省略生命週期 現在我們已經知道每個引用都有生命週期，那是否每一次都要寫出來呢？以下的函式是沒有詮釋生命週期還可以編譯成功的：\nfn first_word(s: \u0026amp;str) -\u0026gt; \u0026amp;str { let bytes = s.as_bytes(); for (i, \u0026amp;item) in bytes.iter().enumerate() { if item == b\u0026#39; \u0026#39; { return \u0026amp;s[0..i]; } } \u0026amp;s[..] } 以上的程式曾經出現在Rust: 所有權 ( Ownership )，那為什麼它可以不用寫出生命週期？\n如果是在早期版本 Rust ( 1.0 之前 )，上面的程式碼就真的無法編譯了，因為那個時候每個引用都必須要顯示生命週期，在當時此函式就會是：\nfn first_word\u0026lt;\u0026#39;a\u0026gt;(s: \u0026amp;\u0026#39;a str) -\u0026gt; \u0026amp;\u0026#39;a str{ 在寫了大量 Rust 程式碼後，Rust 團隊發現開發者會在特定情況反覆輸入同樣的生命週期詮釋，而這些情況都是可預期的，並且遵循一些明確的模式。所以 Rust 團隊將這些模式加入編譯器的程式碼中，讓借用檢查器可以依據這些規則自行推導生命生命週期。\n這個讓 Rust 分析的模式稱為生命週期省略規則 ( lifetime elision rules ) ，當你的程式碼符合該情形時，就可以不用寫出生命週期。\n生命週期省略規則並不是完美的，還是有一些模稜兩可的生命週期，當編譯器無法猜出生命週期時，就會回傳錯誤給你，說明你必須自己指定生命週期\n生命週期省略規則 ( Lifetime elision rules ) 首先要先知道生命週期有兩種：\n在函式或方法參數上的生命週期稱為輸入生命週期 ( input lifetimes ) 在回傳值的生命週期則稱為輸出生命週期 ( output lifetimes ) 編譯器會根據三項規則來推導沒有顯式生命週期的型別。第一個規則適用於輸入生命週期，而第二與第三個規則適用於輸出生命週期。如果三個規則跑完，還是沒有推斷出生命週期，編譯器就會停止並回傳錯誤。\n第一個規則：編譯器會給予每個引用參數一個生命週期參數：\nfn foo\u0026lt;\u0026#39;a\u0026gt;(x: \u0026amp;\u0026#39;a i32) // 1個參數；1個生命週期 fn foo\u0026lt;\u0026#39;a, \u0026#39;b\u0026gt;(x: \u0026amp;\u0026#39;a i32, y: \u0026amp;\u0026#39;b i32) // 2個參數；2個生命週期 第二個規則：如果只有一個輸入生命週期參數，所有輸出生命週期參數就等於此參數：\nfn foo\u0026lt;\u0026#39;a\u0026gt;(x: \u0026amp;\u0026#39;a i32) -\u0026gt; \u0026amp;\u0026#39;a i32 第三個規則：如果輸入的生命週期參數裡有 \u0026amp;self 或 \u0026amp;mut self，很明顯這就是方法 ( methods )，那 self 的生命週期參數就等同於所有輸出生命週期參數。\n現在就可以根據上面的三個規則，來解釋 函式中的泛型生命週期 裡的 longest 函式錯誤的原因了：\nfn longest(x: \u0026amp;str, y: \u0026amp;str) -\u0026gt; \u0026amp;str { 先套用第一個規則，每個參數都有自己的生命週期。而這次有兩個參數：\nfn longest\u0026lt;\u0026#39;a, \u0026#39;b\u0026gt;(x: \u0026amp;\u0026#39;a str, y: \u0026amp;\u0026#39;b str) -\u0026gt; \u0026amp;str { 第二個規則就不適用了，因為這裡不只有一個生命週期參數。第三個規則也不適用，longest 是函式而不是方法。經過三個規則後，編譯器還是無法推斷出型別的生命週期，這也就是程式會出現錯誤的原因。\n屬於方法定義中的生命週期詮釋 那為什麼第三個規則只適用於方法呢？\n結構體欄位的生命週期永遠需要宣告在 impl 關鍵字後方以及結構體名稱後方，因為這些生命週期是結構體型別的一部分。\n在 impl 區塊中，方法所簽名的引用很可能會與結構體欄位的引用生命週期綁定，當然它們也可能是獨立的。\n這裡使用 ImportantExcerpt 來作範例，首先使用一個方法名為 level，其參數就只有 \u0026amp;self 的引用，而回傳值是 i32 並不是引用：\nstruct ImportantExcerpt\u0026lt;\u0026#39;a\u0026gt; { part: \u0026amp;\u0026#39;a str, } impl\u0026lt;\u0026#39;a\u0026gt; ImportantExcerpt\u0026lt;\u0026#39;a\u0026gt; { fn level(\u0026amp;self) -\u0026gt; i32 { 3 } } 以下為第三個生命週期省略規則適用的範例：\nimpl\u0026lt;\u0026#39;a\u0026gt; ImportantExcerpt\u0026lt;\u0026#39;a\u0026gt; { fn announce_and_return_part(\u0026amp;self, announcement: \u0026amp;str) -\u0026gt; \u0026amp;str { println!(\u0026#34;Notice：{}\u0026#34;, announcement); self.part } } 首先，根據第一個生命週期省略規則，給予 \u0026amp;self 與 announcement 各自的生命週期。然後因為其中一個參數是 \u0026amp;self，適用於第三個生命週期省略規則，所以該回傳型別會取得 \u0026amp;self 的生命週期。\n靜態生命週期 有個特殊的生命週期 'static，這表示該引用可以存活在整個程式期間。字串有 'static 生命週期：\nlet s: \u0026amp;\u0026#39;static str = \u0026#34;I have static lifetime\u0026#34;; 此字串的文字會直接儲存在程式的執行檔中，永遠有效。\n泛型型別參數、特徵界限與生命週期的組合 這邊使用一個函式來組合泛型型別參數、特徵界限與生命週期：\nuse std::fmt::Display; fn longest_with_an_announcement\u0026lt;\u0026#39;a, T\u0026gt;( x: \u0026amp;\u0026#39;a str, y: \u0026amp;\u0026#39;a str, ann: T, ) -\u0026gt; \u0026amp;\u0026#39;a str where T: Display, { println!(\u0026#34;Announcement！{}\u0026#34;, ann); if x.len() \u0026gt; y.len() { x } else { y } } 這個函式會比較兩個字串切片，並回傳比較長的那一個 ann 使用泛型型別 T，後面的 where 可以指定 T 有 Display 特徵。這表示這個 ann 參數可以使用 {} 方式印出來 生命週期也是一種泛型，所以生命週期參數 'a 與 泛型型別參數 T 都會一起寫在 \u0026lt;\u0026gt; 裡 結論 生命週期與所有權都是 Rust 管理記憶體很重要的機制，而透過借用檢查器將引用的作用域做比較，可以讓無效的引用在編譯期間就被發現。在三個生命週期省略規則下，Rust 大多的生命週期都可以自動被推導出來，這就跟這就跟型別一樣。\n以上這些分析都是在編譯期間進行的，完全不會影響執行的效能😆！\n","permalink":"https://et860525.github.io/posts/rust-lifetimes/","summary":"\u003cp\u003e\u003cstrong\u003e生命週期 ( lifetimes )\u003c/strong\u003e 會確保我們在需要引用的時候，它們都是有效的。\u003c/p\u003e\n\u003cp\u003e在 Rust 中，每個引用都是有生命週期的，簡單來說就是它的有效範圍。在大多情況下，生命週期都是隱藏且可以推導出來的，如同型別一樣也都是可以推導出來的。當型別有很多種可能的情況下，就要\u003cstrong\u003e詮釋型別\u003c/strong\u003e，同樣在生命週期下，引用以不同方式關聯的話，就要\u003cstrong\u003e詮釋生命週期\u003c/strong\u003e。\u003c/p\u003e","title":"Rust: 生命週期( Lifetimes )"},{"content":"這篇文章會紀錄如何在 Express 專案裡設定 TypeScript。\n先決條件：\n安裝 Node.js ( LTS ) 在你的開發環境上 基本的 Node.js 、 Express 與 TypeScript 知識 專案初始化 建立一個空的資料夾，並初始化 package.json：\nmkdir express-typescript cd express-typescript npm init -y 下載 Express 與開發伺服器的相關套件：\nnpm i express dotenv dotenv 是一個管理環境變數的套件，可以根據環境的不同設定不同的配置 安裝 TypeScript 與 @types 宣告套件：\nnpm i -D typescript @types/express @types/node @types/\u0026lt;package-name\u0026gt;：只要該套件有支援 TypeScript，你就能在直接使用這個方式，下載預先定義好的宣告檔案 -D 是 --save-dev：表示套件只會存在於 devDependencies 都完成後可以檢查 package.json 檔案 (沒有特殊需求，套件的版本以自己的為準)：\n{ \u0026#34;name\u0026#34;: \u0026#34;express-typescript\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;echo \\\u0026#34;Error: no test specified\\\u0026#34; \u0026amp;\u0026amp; exit 1\u0026#34; }, \u0026#34;keywords\u0026#34;: [], \u0026#34;author\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;ISC\u0026#34;, \u0026#34;dependencies\u0026#34;: { \u0026#34;dotenv\u0026#34;: \u0026#34;^16.0.3\u0026#34;, \u0026#34;express\u0026#34;: \u0026#34;^4.18.2\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;@types/express\u0026#34;: \u0026#34;^4.17.17\u0026#34;, \u0026#34;@types/node\u0026#34;: \u0026#34;^18.11.18\u0026#34;, \u0026#34;typescript\u0026#34;: \u0026#34;^4.9.5\u0026#34; } } 產生 TypeScript 的配置文件 使用以下指令來產生 tsconfig.json：\nnpx tsc --init 在輸出可以看到產生的檔案與預設的設定：\nCreated a new tsconfig.json with: target: es2016 module: commonjs strict: true esModuleInterop: true skipLibCheck: true forceConsistentCasingInFileNames: true You can learn more at https://aka.ms/tsconfig 這裡也可以打開 tsconfig.json 來修改自己需要的設定。以下是我的設定：\n{ \u0026#34;compilerOptions\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;es2017\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;commonjs\u0026#34;, \u0026#34;esModuleInterop\u0026#34;: true, \u0026#34;skipLibCheck\u0026#34;: true, \u0026#34;forceConsistentCasingInFileNames\u0026#34;: true, \u0026#34;strict\u0026#34;: true, \u0026#34;rootDir\u0026#34;: \u0026#34;./src\u0026#34;, \u0026#34;outDir\u0026#34;: \u0026#34;./dist\u0026#34;, }, \u0026#34;include\u0026#34;: [\u0026#34;src/**/*.ts\u0026#34;], \u0026#34;exclude\u0026#34;: [\u0026#34;node_modules\u0026#34;, \u0026#34;dist\u0026#34;] } 預設的設定：\ntarget：指定編譯器所產生的 JavaScript version module：編譯 JavaScript 程式碼使用的 modules manager。commonjs 為 Node.js 的標準 strict：嚴格類型檢查選項 esModuleInterop：讓我們能將 ES6 modules 編譯成 commonJS modules skipLibCheck：如果為 true，則會跳過檢查基礎宣告檔案 ( declaration files ) forceConsistentCasingInFileNames：如果為 true，啟用區分大小寫命名文件 新增的設定：\nrootDir：欲編譯的路徑，把該資料夾裡面的 .ts 都編譯成 JavaScript outDir：編譯後輸出檔案的地方 include：納入編譯的範圍 exclude：不納入編譯的範圍 建立 Express app 首先，先在根目錄 ( root ) 下建立一個檔案 .env，這個檔案存放的是敏感資料供 dotenv 來讀取的。該檔案目前會有以下設定：\nPORT=3000 之後再新增檔案 src/app.ts 並輸入下面的程式碼來建立一個伺服器：\nimport express, { Express, Request, Response } from \u0026#39;express\u0026#39;; import dotenv from \u0026#39;dotenv\u0026#39;; dotenv.config(); const app: Express = express(); const port = process.env.PORT; app.get(\u0026#39;/\u0026#39;, (req: Request, res: Response) =\u0026gt; { res.send(\u0026#39;Express + TypeScript Server\u0026#39;); }); app.listen(port, () =\u0026gt; { console.log( `[server]: Server is running at http://localhost:${port}` ); }); 透過 dotenv 就可以讓 port 獲取在 .env 檔案裡的設定 要運行伺服器前必須要先知道一件事情，瀏覽器是無法理解 TypeScript 程式碼的，必須要先將檔案轉成 JavaScript 瀏覽器才能使用。那要如何才能讓 TypeScript 知道哪些檔案是需要編譯的呢？這時候設定 tsconfig.json 就很重要了 (請參考上方 tsconfig.json 所新增的設定)。\n如果已經有設定指定的資料夾，就可以使用下列指令來將 .ts 檔案轉為 .js：\ntsc 轉換完成後就可以運行伺服器了：\nnode dist/app.js 畫面上會顯示 [server]: Server is running at http://localhost:3000 連接到後面的網址，就可以看到伺服器正常運行的畫面了。\n按下 Ctrl+c 就可以停止伺服器\n持續監看 TypeScript 檔案 在開發期間，通常會頻繁的改變網頁內容並觀察其結果，如果以上述方式每一次都要先編譯再執行，肯定會造成許多不方便，而且隨著時間增長程式也會越來越大，所編譯的時間也會相對增加。\n可以使用 nodemon 來解決這個問題。nodemon 是一個幫助開發者的工具，當目錄裡的檔案改變時，它會自動偵測並幫助我們重開應用程式。但是重開應用程式是不夠的，因為 TypeScript 還有要先編譯的問題，所以可以搭配 ts-node 一起使用 (如果沒有安裝此套件，在執行 nodemon 時就會要你安裝)。\n安裝兩個所需要的套件：\nnpm i -D nodemon ts-node 打開 package.json 來編寫腳本：\n\u0026#34;scripts\u0026#34;: { \u0026#34;build\u0026#34;: \u0026#34;tsc\u0026#34;, \u0026#34;dev\u0026#34;: \u0026#34;NODE_ENV=development nodemon ./src/app.ts\u0026#34; } 運行腳本：\nnpm run dev 你可以嘗試改變 res.send('Express + TypeScript Server'); 裡的文字，儲存後重整網頁就能看到改變的結果，就不需要進行編譯再執行的動作了。\n結論 以上就是建立一個最基本 Express + TypeScript 的方式。\n","permalink":"https://et860525.github.io/posts/typescript-express-initialization/","summary":"\u003cp\u003e這篇文章會紀錄如何在 \u003ca href=\"https://expressjs.com/\"\u003eExpress\u003c/a\u003e 專案裡設定 \u003ca href=\"https://www.typescriptlang.org/\"\u003eTypeScript\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e先決條件：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e安裝 \u003ca href=\"https://nodejs.org/en/\"\u003eNode.js\u003c/a\u003e ( LTS ) 在你的開發環境上\u003c/li\u003e\n\u003cli\u003e基本的 \u003ccode\u003eNode.js\u003c/code\u003e 、 \u003ccode\u003eExpress\u003c/code\u003e 與 \u003ccode\u003eTypeScript\u003c/code\u003e 知識\u003c/li\u003e\n\u003c/ul\u003e","title":"TypeScript: 初始化 Express 專案"},{"content":"特徵( trait )，是定義特定型別與其他型別共享的功能。可以使用特徵界限 ( trait bounds ) 來指定泛型型別為擁有特定行為的任意型別。\n特徵類似於其他語言常稱作介面 ( interfaces ) 的功能，但還是有些差異。\n定義特徵 舉例，現在我們有兩個結構體各自擁有不同種類與不同數量的文字：\nNewsArticle 儲存特定地點的新聞故事 Tweet 則有最多 280 字元的內容，且有個欄位來判斷是全新的推文、轉推或其他推文的回覆。 我們想要建立一個多媒體資料庫，來顯示可能存在於 NewsArticle 或 Tweet 實例的總結 ( summary )。要達成這個目的，我們會呼叫該實例的 summarize 方法來獲得實例裡的 summary。\n新建立一個檔案為 src/lib.rs，並在此使用 trait 關鍵字定義一個 Summary 特徵：\npub trait Summary { fn summarize(\u0026amp;self) -\u0026gt; String; } fn summarize(\u0026amp;self) -\u0026gt; String 宣告方法簽名來描述有實作此特徵的型別行為 特徵本體中可以有多個方法，每行會有一個方法簽名並都以分號做結尾。\n每個有實作此特徵的型別，都必須提供其自訂行為的方法本體。編譯器會強制要求任何有 Summary 特徵的型別都要有定義相同簽名的 summarize 方法。\n型別實作特徵 在 src/lib.rs 中定義 Summary 特徵完成後，就可以在資料庫裡實作它：\npub trait Summary { fn summarize(\u0026amp;self) -\u0026gt; String; } pub struct NewsArticle { pub headline: String, pub location: String, pub author: String, pub content: String, } impl Summary for NewsArticle { fn summarize(\u0026amp;self) -\u0026gt; String { format!(\u0026#34;{} {} 著 ({})\u0026#34;, self.headline, self.author, self.location) } } pub struct Tweet { pub username: String, pub content: String, pub reply: bool, pub retweet: bool, } impl Summary for Tweet { fn summarize(\u0026amp;self) -\u0026gt; String { format!(\u0026#34;{}: {}\u0026#34;, self.username, self.content) } } 在 impl 之後我們加上想要實作的特徵，然後使用 for 關鍵字加上想要實作的型別名稱。並在 impl 區塊裡定義特徵所指定的方法。\n這裡使用的 rust_aggregator 是一開始 cargo new \u0026lt;name\u0026gt; 的名字，我們已經在函式庫裡加入對 NewsArticle 和 Tweet 實作 Summary 特徵，如果是 crate 的使用者只要直接呼叫即可。唯一的不同就是，使用的特徵也必須加入到作用域中。\n以下是我的 rust_aggregator 函式庫的 main.rs：\nuse rust_aggregator::{self, Summary, Tweet}; fn main() { let tweet = Tweet { username: String::from(\u0026#34;horse_ebooks\u0026#34;), content: String::from( \u0026#34;of course, as you probably already know, people\u0026#34;, ), reply: false, retweet: false, }; println!(\u0026#34;1 則新推文：{}\u0026#34;, tweet.summarize()); } 此程式碼會印出：1 則新推文：horse_ebooks: of course, as you probably alreadyknow, people。\n預設實作 將特徵內的一些方法預先定義實作，就不用要求型別實作這些方法了。如果特定型別想要更改特徵內方法的實作，直接寫上方法就能覆蓋預設的實作。以下是定義預設實作：\npub trait Summary { fn summarize(\u0026amp;self) -\u0026gt; String { String::from(\u0026#34;(閱讀更多...)\u0026#34;) } } 當 summarize 方法此時有預設實作，就不會強制要求型別需要設定此方法：\nfn main() { let article = NewsArticle { headline: String::from(\u0026#34;Penguins win the Stanley Cup Championship!\u0026#34;), location: String::from(\u0026#34;Pittsburgh, PA, USA\u0026#34;), author: String::from(\u0026#34;Iceburgh\u0026#34;), content: String::from( \u0026#34;The Pittsburgh Penguins once again are the best \\ hockey team in the NHL.\u0026#34;, ), }; println!(\u0026#34;有新文章發佈！{}\u0026#34;, article.summarize()); } 如果 NewsArticle 沒有實作 summarize 方法，此程式碼就會印出 有新文章發佈！(閱讀更多...)。\n特徵作為參數 使用特徵來定義函式所接受的參數。在 Summary 特徵定義一個新的 notify 函式，它會使用自己的參數 item 來呼叫 summarize 方法，所以此參數的型別會預期有 Summary 特徵。\npub fn notify(item: \u0026amp;impl Summary) { println!(\u0026#34;頭條新聞！{}\u0026#34;, item.summarize()); } item 參數指定實際型別用的是 impl 關鍵字加上特徵名稱，表示此參數會接受任何有實作指定特徵的型別 ( NewsArticle 或 Tweet ) 。但如果用其他型別像是 String 或 i32 來呼叫此程式碼則會無法編譯，因為那些型別沒有實作 Summary。\n這能讓函式的參數只接受特定特徵的型別\n特徵界限語法 impl Trait 是一個更長格式的語法糖，而這個格式稱為特徵界限 ( trait bound )，它長得像：\npub fn notify\u0026lt;T: Summary\u0026gt;(item: \u0026amp;T) { println!(\u0026#34;頭條新聞！{}\u0026#34;, item.summarize()); } impl Trait 語法比較方便，且在簡單的案例中可以讓程式碼比較簡潔，而特徵界限適合其他複雜的案例。\n舉例參數是兩個實作 Summary 參數，使用 impl Trait：\npub fn notify(item1: \u0026amp;impl Summary, item2: \u0026amp;impl Summary) { 如果函式允許 item1 與 item2 是不同型別，就可使用 impl Trait。但如果兩個參數是同一型別，就要改成特徵界限 ( trait bound ) 的方式：\npub fn notify\u0026lt;T: Summary\u0026gt;(item1: \u0026amp;T, item2: \u0026amp;T) { 這樣 item1 與 item2 的型別就必須要相同了。\n使用「+」指定多個特徵界限 在上一章泛型有提到用兩個特徵的函式：\nfn largest\u0026lt;T: PartialOrd + Copy\u0026gt;(list: \u0026amp;[T]) -\u0026gt; T { 這兩個特徵分別為：\nPartialOrd 判斷邏輯 Copy 將變數指派給另一個變數 這個方法也一樣可以用在參數裡。假設 notify 中的 item 不只能呼叫 summarize 方法，還能顯示格式化訊息的話，也可以使用 +：\nimpl Trait pub fn notify(item: \u0026amp;(impl Summary + Display)) { 特徵界限 pub fn notify\u0026lt;T: Summary + Display\u0026gt;(item: \u0026amp;T) 使用「where」使特徵界限更清楚 如果今天每個泛型都有自己的特徵界限，會造成函式簽名難以閱讀：\nfn some_function\u0026lt;T: Display + Clone, U: Clone + Debug\u0026gt;(t: \u0026amp;T, u: \u0026amp;U) -\u0026gt; i32 { 使用 where 讓一切看起來不那麼複雜：\nfn some_function\u0026lt;T, U\u0026gt;(t: \u0026amp;T, u: \u0026amp;U) -\u0026gt; i32 where { T: Display + Clone, U: Clone + Debug, } 回傳有實作特徵的型別 在回傳型別的位置使用 impl Trait 語法，來回傳某個有實作特徵的型別：\nfn returns_summarizable() -\u0026gt; impl Summary { Tweet { username: String::from(\u0026#34;horse_ebooks\u0026#34;), content: String::from( \u0026#34;of course, as you probably already know, people\u0026#34;, ), reply: false, retweet: false, } } 但是如果使用 impl Trait 的話就只能回傳單一型別。舉例來說，雖然程式碼指定回傳的型別為 impl Summary，但是將程式碼寫成可能會回傳 NewsArticle 或 Tweet 就會無法執行：\nfn returns_summarizable(switch: bool) -\u0026gt; impl Summary { if switch { NewsArticle { headline: String::from( \u0026#34;Penguins win the Stanley Cup Championship!\u0026#34;, ), location: String::from(\u0026#34;Pittsburgh, PA, USA\u0026#34;), author: String::from(\u0026#34;Iceburgh\u0026#34;), content: String::from( \u0026#34;The Pittsburgh Penguins once again are the best \\ hockey team in the NHL.\u0026#34;, ), } } else { Tweet { username: String::from(\u0026#34;horse_ebooks\u0026#34;), content: String::from( \u0026#34;of course, as you probably already know, people\u0026#34;, ), reply: false, retweet: false, } } } 對於可能返回 NewsArticle 或 Tweet 的話是不被允許的，因為 impl Trait 語法會限制在編譯器中最終決定的型別。\n透過特徵界限來選擇性實作方法 在有使用泛型型別參數 impl 區塊中使用特徵界限，就可以有選擇性的實作特定型別的實作方法：\nuse std::fmt::Display; struct Pair\u0026lt;T\u0026gt; { x: T, y: T, } impl\u0026lt;T\u0026gt; Pair\u0026lt;T\u0026gt; { fn new(x: T, y: T) -\u0026gt; Self { Self { x, y } } } impl\u0026lt;T: Display + PartialOrd\u0026gt; Pair\u0026lt;T\u0026gt; { fn cmp_display(\u0026amp;self) { if self.x \u0026gt;= self.y { println!(\u0026#34;最大的是 x = {}\u0026#34;, self.x); } else { println!(\u0026#34;最大的是 y = {}\u0026#34;, self.y); } } } 簡單來說，第一個 impl\u0026lt;T\u0026gt; 因為它沒有任何特徵，所有型別的 Pair 都可以使用這個方法；第二個 impl 則有限定型別，如果型別的特徵是 \u0026lt;T: Display + PartialOrd\u0026gt; 那它就可以使用，如果沒有則無法使用這個方法。\n而這種滿足特徵界限的型別實作特徵，則稱之為全面實作 ( blanket implementations )，這被廣泛的使用在 Rust 標準函式中。舉個例子，標準函式庫會對任何有實作 Display 特徵的型別實作 ToString，以下是類似於標準函式庫中的 impl 區塊：\nimpl\u0026lt;T: Display\u0026gt; ToString for T { // --省略-- } 標準函式庫有此全面實作，這樣就能將整數與字元轉為 String：\nlet s1 = 3.to_string(); let s2 = \u0026#39;c\u0026#39;.to_string(); 結論 上述有提到 Trait與其他程式語言的 Interface 有些不同，其中最大的不同在於：Interface 主要是根據特定的 object 來設定接口的；Trait 則可以對現有的型別來實現實作：\ntrait Hash { fn hash(\u0026amp;self) -\u0026gt; u64; } impl Hash for bool { fn hash(\u0026amp;self) -\u0026gt; u64 { if *self { 0 } else { 1 } } } impl Hash for i64 { fn hash(\u0026amp;self) -\u0026gt; u64 { *self as u64 } } 在 Hash 的作用域內就可以使用 true.hash() 這樣的寫法。\n引用 特徵：定義共同行為 Traits: Defining Shared Behavior Abstraction without overhead: traits in Rust ","permalink":"https://et860525.github.io/posts/rust-trait/","summary":"\u003cp\u003e特徵( trait )，是定義特定型別與其他型別共享的功能。可以使用\u003cstrong\u003e特徵界限 ( trait bounds )\u003c/strong\u003e 來指定泛型型別為擁有特定行為的任意型別。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e特徵類似於其他語言常稱作\u003cstrong\u003e介面 ( interfaces )\u003c/strong\u003e 的功能，但還是有些差異。\u003c/p\u003e\n\u003c/blockquote\u003e","title":"Rust: 特徵( Trait )"},{"content":"泛型 ( generics )，實際型別或屬性的抽象表示。舉例來說，String 和 i32 這兩個不同型別的資料都可以被存到 Vec 結構體建立的實例中，不需要針對型別來做分別，只要使用 Vec\u0026lt;String\u0026gt; 或 Vec\u0026lt;i32\u0026gt;，這是因為 Vec 結構體使用了泛型。\n泛型就是 參數多型 ( parametric polymorphism )，在定義型別或函數的時候不去明確指定具體的型別，而是以參數的形式來傳入型別，這可以讓程式設計更為彈性。\n以下先來看泛型在各個地方中如何定義。\n函式中定義 用一個找出陣列最大元素值的程式來實作泛型，首先，先來看它原本的樣子：\nfn largest_i32(list: \u0026amp;[i32]) -\u0026gt; i32 { let mut largest = list[0]; for \u0026amp;item in list.iter() { if item \u0026gt; largest { largest = item; } } largest } fn largest_char(list: \u0026amp;[char]) -\u0026gt; char { let mut largest = list[0]; for \u0026amp;item in list.iter() { if item \u0026gt; largest { largest = item; } } largest } fn main() { let int_list = vec![34, 50, 25, 100, 65]; let result = largest_i32(\u0026amp;int_list); println!(\u0026#34;The largest integer number is {}\u0026#34;, result); let char_list = vec![\u0026#39;y\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;q\u0026#39;]; let result = largest_char(\u0026amp;char_list); println!(\u0026#34;The largest char is {}\u0026#34;, result); } 兩個 largest_i32、largest_char，可以分別從 32位元的有號整數陣列切片、字元陣列切片中找出最大的元素並回傳出來。基本上函式裡面的程式碼都是相同的，只是因為我們要處理不同型別的資料所以寫了三次，如果要連 i8、i16、i64、u8、u16、u32、u64、f32 等型別的陣列切片都寫，那不就要再多寫8次，所以 Rust 提供泛型來解決這個問題，以下是改為泛型示範：\nfn largest\u0026lt;T\u0026gt;(list: \u0026amp;[T]) -\u0026gt; T { let mut largest = list[0]; for \u0026amp;item in list.iter() { if item \u0026gt; largest { largest = item; } } largest } fn main() { let int_list = vec![34, 50, 25, 100, 65]; let result = largest(\u0026amp;int_list); println!(\u0026#34;The largest integer number is {}\u0026#34;, result); let char_list = vec![\u0026#39;y\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;q\u0026#39;]; let result = largest(\u0026amp;char_list); println!(\u0026#34;The largest char is {}\u0026#34;, result); } 在呼叫 largest\u0026lt;T\u0026gt; 函式時，編譯器會在編譯階段時自動判斷泛型的第一個參數型別，來決定 T 會是什麼型別。如果不想要讓編譯器自己判定，那就在呼叫函式時直接指定泛型的型別：\nfn largest\u0026lt;T\u0026gt;(list: \u0026amp;[T]) -\u0026gt; T { // 略... } fn main() { let int_list = vec![34, 50, 25, 100, 65]; let result = largest::\u0026lt;i32\u0026gt;(\u0026amp;int_list); println!(\u0026#34;The largest integer number is {}\u0026#34;, result); let char_list = vec![\u0026#39;y\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;q\u0026#39;]; let result = largest::\u0026lt;char\u0026gt;(\u0026amp;char_list); println!(\u0026#34;The largest char is {}\u0026#34;, result); } 不管如何，上述程式碼執行都會出現錯誤。這是因為要將值進行大於小於的判定之類的邏輯判斷，該值就必須要有 PartialOrd 的特徵 ( trait ) 。綜上所知，泛型的 T 可以是任何型別，但它不一定會是 PartialOrd 特徵，所以程式碼才會編譯失敗。為了要讓編譯器確定 T 要有這個 PartialOrd 特徵，我們必須事先明確定義，就像定義一般函式參數的型別：\nfn largest\u0026lt;T: PartialOrd\u0026gt;(list: \u0026amp;[T]) -\u0026gt; T { // 加上 PartialOrd 特徵 let mut largest = list[0]; for \u0026amp;item in list.iter() { if item \u0026gt; largest { largest = item; } } largest } fn main() { // 略... } 再編譯一次還是會有錯誤，這是因為第 2行有將陣列的元素指派給 largest 變數，這種 把變數指派給另一個變數就表示這個型別有 Copy 的特徵。所以還要再讓 T 知道該型別還會有 Copy 特徵：\nfn largest\u0026lt;T: PartialOrd + Copy\u0026gt;(list: \u0026amp;[T]) -\u0026gt; T { // 再加上 Copy 特徵 let mut largest = list[0]; for \u0026amp;item in list.iter() { if item \u0026gt; largest { largest = item; } } largest } fn main() { // 略... } 這樣程式就可以執行了：\n❯ cargo run Compiling hello_cargo v0.1.0 (file:///projects//hello_cargo) Finished dev [unoptimized + debuginfo] target(s) in 0.23s Running `target/debug/hello_cargo` The largest integer number is 100 The largest char is y 結構體中定義 在結構體的名稱右邊加上 \u0026lt;\u0026gt; 語法來定義泛型：\nstruct Point\u0026lt;T\u0026gt; { x: T, y: T } fn main() { let integer = Point { x: 5, y: 10 }; let float = Point { x: 1.0, y: 4.0 }; } 編譯器在編譯期間也會自動判斷泛型第一個接觸的值，來決定型別。因此 integer 的泛型為 i32；float 的泛型為 f64。\n另一個例子：\nstruct Point\u0026lt;T\u0026gt; { x: T, y: T } fn main() { let wont_work = Point { x: 5, y: 4.0 }; } 以上程式就會發生錯誤，因為泛型第一個接觸的值是 5 也就是 i32 型別，此時 Point 的 x 與 y 的值都一定要是 i32，自然也就不能存取 4.0 這個 f64 的型別。\n要解決上面的問題，可以使用兩個泛型參數：\nstruct Point\u0026lt;T, U\u0026gt; { x: T, y: U } fn main() { let both_integer = Point { x: 5, y: 10 }; let both_float = Point { x: 1.0, y: 4.0 }; let integer_and_float = Point { x: 5, y: 4.0 }; } 枚舉中定義 像是 Option 枚舉 與 Result 枚舉：\nenum Option\u0026lt;T\u0026gt; { Some(T), None } enum Result\u0026lt;T, E\u0026gt; { Ok(T), Err(E) } 方法中定義 impl 關鍵字右邊也可以加上 \u0026lt;\u0026gt; 來定義泛型要使用的參數：\nstruct Point\u0026lt;T\u0026gt; { x: T, y: T, } impl\u0026lt;T\u0026gt; Point\u0026lt;T\u0026gt; { fn x(\u0026amp;self) -\u0026gt; \u0026amp;T { \u0026amp;self.x } } fn main() { let p = Point { x: 5, y: 10 }; println!(\u0026#34;p.x = {}\u0026#34;, p.x()); } impl 也可以只針對的特定的型別，來實作關聯函式和方法：\nstruct Point\u0026lt;T\u0026gt; { x: T, y: T, } impl\u0026lt;T\u0026gt; Point\u0026lt;T\u0026gt; { fn x(\u0026amp;self) -\u0026gt; \u0026amp;T { \u0026amp;self.x } } impl Point\u0026lt;f64\u0026gt; { fn distance_from_origin(\u0026amp;self) -\u0026gt; f64 { (self.x.powi(2) + self.y.powi(2)).sqrt() } } impl Point\u0026lt;i32\u0026gt; { fn distance_from_origin(\u0026amp;self) -\u0026gt; f64 { ((self.x.pow(2) + self.y.pow(2)) as f64).sqrt() } } fn main() { let p = Point { x: 3.0, y: 4.0 }; println!(\u0026#34;distance = {}\u0026#34;, p.distance_from_origin()); let p = Point { x: 5, y: 12 }; println!(\u0026#34;distance = {}\u0026#34;, p.distance_from_origin()); } 使用泛型的程式碼效能 Rust 的泛型不會有任何額外的運算效能的耗損。\nRust 在編譯時對使用泛型的程式碼進行單態化 ( monomorphization ) 。單態化能讓泛型轉換成特定程式碼的過程，並在編譯時填入實際型別。簡單來說，它會根據填入的實際型別，自動產生相應的程式碼。\n以下示範標準函式庫的泛型枚舉 Option\u0026lt;T\u0026gt; 是如何做到的：\nlet integer = Some(5); let float = Some(5.0); Rust 在編譯上面的程式碼時，就會進行單態化。上面的型態分別是 i32 與 f64，而編譯器會自動產生 Option_i32 和 Option_f64 的結構體 ( 編譯器實際的名稱與這邊的不同 )：\nenum Option_i32 { Some(i32), None, } enum Option_f64 { Some(f64), None, } fn main() { let integer = Option_i32::Some(5); let float = Option_f64::Some(5.0); } 因此，使用泛型的時候，程式在執行階段完全不需要使用額外的運算資源去進行型別的檢查，因為這些工作都在編譯期間自動完成了。\n結論 在 TypeScript 裡也有泛型的機制，所以學習起來並不那麼吃力。泛型就是為了解決這種不同型別但是程式碼重複的情況，加上下個章節會提到的特徵 ( trait ) 來限定哪種型別能使用。\n引用 泛型資料型別 ","permalink":"https://et860525.github.io/posts/rust-generics/","summary":"\u003cp\u003e泛型 ( generics )，實際型別或屬性的抽象表示。舉例來說，\u003ccode\u003eString\u003c/code\u003e 和 \u003ccode\u003ei32\u003c/code\u003e 這兩個不同型別的資料都可以被存到 \u003ca href=\"https://doc.rust-lang.org/std/vec/struct.Vec.html\"\u003eVec 結構體\u003c/a\u003e建立的實例中，不需要針對型別來做分別，只要使用 \u003ccode\u003eVec\u0026lt;String\u0026gt;\u003c/code\u003e 或 \u003ccode\u003eVec\u0026lt;i32\u0026gt;\u003c/code\u003e，這是因為 \u003ccode\u003eVec\u003c/code\u003e 結構體使用了泛型。\u003c/p\u003e\n\u003cp\u003e泛型就是 \u003cstrong\u003e參數多型 ( parametric polymorphism )\u003c/strong\u003e，在定義型別或函數的時候不去明確指定具體的型別，而是以參數的形式來傳入型別，這可以讓程式設計更為彈性。\u003c/p\u003e\n\u003cp\u003e以下先來看泛型在各個地方中如何定義。\u003c/p\u003e","title":"Rust: 泛型( Generics )"},{"content":"在一開始撰寫文章時，本來想以寫比較久的 TypeScript 來做部落格的開頭文章，但在過年前接觸到 Rust 這個程式語言，就順勢把最近學到的東西放上來。等到把在 TypeScript 遇到的問題整理一下再寫成一個系列放上來。\n所有權 ( ownership ) 是 Rust 用來 管理程式記憶體的一系列規則，讓 Rust 不需要垃圾回收 ( Garbage collection ) 就可以保障記憶體的安全。\n所有程式都需要在執行時管理它們使用記憶體的方式，這裡有常見的兩種：\n語言本身就有垃圾回收機制，在程式執行時不斷尋找不再使用的記憶體 開發者必須親自分配和釋放記憶體 而 Rust 選擇第三種方式：記憶體由所有權系統管理，編譯器會在編譯時加上一些規則檢查，如果有違規，程式就無法編譯。\n所有權的規則完全不會降低執行程式的速度\n堆疊 ( Stack ) 與堆積 ( Heap ) 堆疊與堆積都是提供程式碼在執行時能夠使用的記憶體部分，但組成的方式不一樣。\n堆疊 ( Stack ) 會按照順序依序排列它們，並以相反順序移除，這也稱之為 後進先出 ( last in, first out )。所有在堆疊上的資料都必須是已知的固定大小，在編譯期間屬於未知或可能變更大小的資料則必須儲存在於堆積。\n想像堆疊是盤子，當加入盤子時只能疊在最上方，想要拿走盤子也只能拿最上面的盤子，想從中間或最下面插入或拿走盤子都不行。\n堆積 ( Heap ) 相比堆疊就沒有組織，當資料放進堆積時，記憶體分配器 ( memory allocator )會找到一塊夠大的空位，並標記已占用，然後回傳一個指標 ( pointer ) 指向該位址。這一整個過程稱之為 堆積上分配 ( allocating on the heap ) 或簡稱為分配。也因為指標是固定的大小，它可以被存在堆疊上，當需要存取實際的資料時，就透過指標去獲得即可。\n資料在堆疊與堆積的比較：\n將資料推入堆疊會比堆積分配還快，因為分配器不用去尋找空位，其位置永遠在堆疊的最上方。堆積就需要比較多的步驟，分配器必須要先找到一個足夠的空位，並做紀錄為下一次分配做準備。\n獲得資料的時間也是堆疊最快，因為堆積必須要透過指標才能找到。如果處理器與記憶體間跳轉的時間越少，則速度就越快。\n理解所有權主要就是為了管理堆積。\n所有權規則 Rust 中每個數值都有個擁有者 ( owner )。 同時間只能有一個擁有者。 當擁有者離開作用域 ( scope ) 時，數值就會被丟棄。 作用域 ( scope ) fn main() { { // s 在此處無效，因為它還沒宣告 let s = \u0026#34;hello\u0026#34;; // s 在此開始視為有效 // 使用 s } // 此作用域結束， s 不再有效 } 兩個重要的時間點：\n當 s 進入作用域時，它是有效的。 它持續被視為有效直到它離開作用域為止。 記憶體與分配 而對於 String 型別來說，為了要能夠支援可變性 (改變文字長度大小)，我們需要在堆積 ( Heap ) 上分配一塊編譯時未知大小的記憶體來儲存這樣的內容：\n記憶體分配器必須在執行時請求記憶體 我們不再需要這個 String 時，我們需要以某種方法將此記憶體還給分配器 第一部分，當呼叫 String::from ，他會請求分配一塊它需要的記憶體，這在其他程式語言都一樣。\n第二部分，在擁有垃圾回收機制(garbage collector, GC) 的語言中，GC 會追蹤並清理不再使用的記憶體。沒有 GC 的話，就必須自己去識別哪些記憶體不再使用，並且釋放它們。如果忘記釋放會造成記憶體的浪費，太早釋放則會拿到無效的變數，如果釋放了兩次，就會造成程式錯誤。\nRust 的方法是，當記憶體在擁有它的變數離開作用域時就會自動釋放：\nfn main() { { let s = String::from(\u0026#34;hello\u0026#34;); // s 在此開始視為有效 // 使用 s } // 此作用域結束 // s 不再有效 } 當 s 離開作用域，String 所需要的記憶體釋放回分配器。當離開作用域，Rust 會幫我們呼叫一個特殊函式 drop 來釋放記憶體。\n變數與資料互動的方式：移動（Move） fn main() { let x = 5; let y = x; } 一般來說，x 取得數值 5，然後 copy 一份給 y。\n但在 String 的版本，就不只是拷貝那麼簡單\nfn main() { let s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = s1; println!(\u0026#34;{}, world!\u0026#34;, s1); } 這就要先了解 String 的架構，一個 String 由三個部分組成：\n指向儲存字串內容記憶體的指標 它的長度：是 String 內容在記憶體以位元組為單位所佔用的大小 它的容量：是 String 從分配器以位元組為單位取得的總記憶體量 所以將 s1 賦值給 s2，String 的資料會被拷貝，不過這裡指的是拷貝堆疊上的指標、長度和容量。\n如果 Rust 直接拷貝堆積的資料，s2 = s1 的動作花費會變得非常昂貴，當堆積上的資料非常龐大時，是十分影響效能的。\n先前有提到當變數離開作用域時，Rust 會自動呼叫 drop 函式來清理堆積上的資料。而當 s2 與 s1 離開作用域時，它們都會嘗試釋放相同的記憶體，這被稱為 雙重釋放 ( double free )，釋放記憶體兩次可能會導致記憶體損壞，進而造成安全漏洞。\n所以為了保障記憶體安全，let s2 = s1; 後 s1 就不再有效，所以在 s2 建立後再使用 s1 就會無法執行：\nlet s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = s1; println!(\u0026#34;{}, world!\u0026#34;, s1); Rust 會跳出錯誤防止你執行：\n$ cargo run Compiling ownership v0.1.0 (file:///projects/ownership) error[E0382]: borrow of moved value: `s1` --\u0026gt; src/main.rs:5:28 | 2 | let s1 = String::from(\u0026#34;hello\u0026#34;); | -- move occurs because `s1` has type `String`, which does not implement the `Copy` trait 3 | let s2 = s1; | -- value moved here 4 | 5 | println!(\u0026#34;{}, world!\u0026#34;, s1); | ^^ value borrowed here after move | = note: this error originates in the macro `$crate::format_args_nl` which comes from the expansion of the macro `println` (in Nightly builds, run with -Z macro-backtrace for more info) For more information about this error, try `rustc --explain E0382`. error: could not compile `ownership` due to previous error 變數與資料互動的方式：克隆（Clone） 如果需要深拷貝 ( deep copy )的話，使用 clone：\nfn main() { let s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = s1.clone(); println!(\u0026#34;s1 = {}, s2 = {}\u0026#34;, s1, s2); } 這樣 s1 與 s2 都能使用。\n只在堆疊上的資料：拷貝（Copy） fn main() { let x = 5; let y = x; println!(\u0026#34;x = {}, y = {}\u0026#34;, x, y); } Q: 那為什麼上面的程式碼會成立？沒有呼叫 clone，但 x 卻仍是有效的，沒有移動到 y。\nA: 因為像整數這樣的型別在編譯時是已知大小，所以只會存在在堆疊上。\nRust 有個特別的標記叫做 Copy 特徵（trait）可以用在標記像整數這樣存在堆疊上的型別。如果一個型別有實作 ( implement ) Drop 特徵的話，Rust 不會允許我們讓此型別擁有 Copy 特徵。\n哪些型別有實作 Copy 特徵呢？基本原則是任何簡單地純量數值都可以實作 Copy\n所有整數型別像是 u32。 布林型別 bool，它只有數值 true 與 false。 所有浮點數型別像是 f64。 字元型別 char。 元組，不過包含的型別也都要有實作 Copy 才行。比如 (i32, i32) 就有實作 Copy，但 (i32, String) 則無。 所有權與函式 傳遞數值給函式的方式和賦值給變數是類似的。\nfn main() { let s = String::from(\u0026#34;hello\u0026#34;); // s 進入作用域 takes_ownership(s); // s 的值進入函式 // 所以 s 也在此無效 let x = 5; // x 進入作用域 makes_copy(x); // x 本該移動進函式裡 // 但 i32 有 Copy，所以 x 可繼續使用 } fn takes_ownership(some_string: String) { // some_string 進入作用域 println!(\u0026#34;{}\u0026#34;, some_string); } // some_string 在此離開作用域並呼叫 `drop` // 佔用的記憶體被釋放 fn makes_copy(some_integer: i32) { // some_integer 進入作用域 println!(\u0026#34;{}\u0026#34;, some_integer); } // some_integer 在此離開作用域，沒有任何動作發生 如果呼叫 takes_ownership 後使用 s，Rust 會拋出編譯時期錯誤。\n回傳值與作用域 變數的所有權每次都會遵照相同的模式，只要賦值給其他變數就會移動。當有堆積的變數離開作用域，該值就會被 drop 清除，除非資料的所有權被轉移到其他變數。\n使用以下方法來回傳參數的所有值：\nfn main() { let s1 = String::from(\u0026#34;hello\u0026#34;); let (s2, len) = calculate_length(s1); // s1 移入 calculate_length // 將所有權透過回傳給 s2 println!(\u0026#34;\u0026#39;{}\u0026#39; 的長度為 {}。\u0026#34;, s2, len); } fn calculate_length(s: String) -\u0026gt; (String, usize) { let length = s.len(); // len() 回傳 String 的長度 (s, length) } 以上是正確的做法，但如果要重複使用這個值，每一次都要傳進傳出就很麻煩。所以 Rust 還有提供一個在不移轉所有權的情況下使用數值，稱為 引用 ( references )。\n引用與借用 引用 ( references ) 就像是指向某個地址的指標，我們可以追蹤存取到該處儲存的資訊，而讓該地址被其他變數所擁有，與指標不同的是，引用保證所指向的特定型別的數值一定是有效的。\nfn main() { let s1 = String::from(\u0026#34;hello\u0026#34;); let len = calculate_length(\u0026amp;s1); println!(\u0026#34;\u0026#39;{}\u0026#39; 的長度為 {}。\u0026#34;, s1, len); } fn calculate_length(s: \u0026amp;String) -\u0026gt; usize { s.len() } \u0026amp;s1 語法讓我們可以建立一個指向 s1 數值的引用，但不會擁有它。也因為它沒有所有權，它所指向的資料在引用不再使用後並不會被丟棄。\n建立引用這樣的動作叫做借用（borrowing）。就像現實世界一樣，如果有人擁有一個東西，他可以借用給你。當你使用完後，你就還給他，你並不擁有它。\n以下程式碼能不能執行？\nfn main() { let s = String::from(\u0026#34;hello\u0026#34;); change(\u0026amp;s); } fn change(some_string: \u0026amp;String) { some_string.push_str(\u0026#34;, world\u0026#34;); } 答案是不行，因為它只是借用，所以不能改變引用的值。\n可變引用 如果要讓上方的程式碼，改變引用的值：\nfn main() { let mut s = String::from(\u0026#34;hello\u0026#34;); change(\u0026amp;mut s); } fn change(some_string: \u0026amp;mut String) { some_string.push_str(\u0026#34;, world\u0026#34;); } 先將 s 加入 mut 讓他能被改變 change 函式的地方建立了一個可變引用 \u0026amp;mut s change 函式的新簽章為 some_string: \u0026amp;mut String 來接收這個可變引用 可變引用有一個大限制：對相同的變數可變引用只能有一個。如果嘗試建立兩個可變引用就會失敗：\nfn main() { let mut s = String::from(\u0026#34;hello\u0026#34;); let r1 = \u0026amp;mut s; let r2 = \u0026amp;mut s; println!(\u0026#34;{}, {}\u0026#34;, r1, r2); } 錯誤資訊：\n$ cargo run Compiling ownership v0.1.0 (file:///projects/ownership) error[E0499]: cannot borrow `s` as mutable more than once at a time --\u0026gt; src/main.rs:5:14 | 4 | let r1 = \u0026amp;mut s; | ------ first mutable borrow occurs here 5 | let r2 = \u0026amp;mut s; | ^^^^^^ second mutable borrow occurs here 6 | 7 | println!(\u0026#34;{}, {}\u0026#34;, r1, r2); | -- first borrow later used here For more information about this error, try `rustc --explain E0499`. error: could not compile `ownership` due to previous error 這項限制的好處是 Rust 可以在編譯時期就防止資料競爭 ( data races )。它會由以下三種行為引發：\n同時有兩個以上的指標存取同個資料。 至少有一個指標在寫入資料。 沒有針對資料的同步存取機制。 資料競爭會造成未定義行為 ( undefined behavior )，而且在執行時你通常是很難診斷並修正的，而 Rust 能阻止這樣的問題，它不會讓有資料競爭的程式碼編譯。\n簡單來說，不要同時擁有同一個引用就可執行：\nfn main() { let mut s = String::from(\u0026#34;hello\u0026#34;); { let r1 = \u0026amp;mut s; } // r1 離開作用域，所以建立新的引用也不會有問題 let r2 = \u0026amp;mut s; } 可變引用和不可變引用，不能同時使用：\nfn main() { let mut s = String::from(\u0026#34;hello\u0026#34;); let r1 = \u0026amp;s; // 沒問題 let r2 = \u0026amp;s; // 沒問題 let r3 = \u0026amp;mut s; // 有問題！ println!(\u0026#34;{}, {}, and {}\u0026#34;, r1, r2, r3); } 這是因為，不可變引用的使用者不希望有人改變了值，並造成錯誤。不過多個不可變引用是沒問題的，因為大家都不能變更值。\n引用的作用域始於它被宣告的地方，一直到它最後一次引用被使用為止：\nfn main() { let mut s = String::from(\u0026#34;hello\u0026#34;); let r1 = \u0026amp;s; // 沒問題 let r2 = \u0026amp;s; // 沒問題 println!(\u0026#34;{} and {}\u0026#34;, r1, r2); // 變數 r1 和 r2 將不再使用 let r3 = \u0026amp;mut s; // 沒問題 println!(\u0026#34;{}\u0026#34;, r3); } 迷途引用 ( Dangling references ) 有指標的程式語言，就會不小心產生 迷途指標 ( dangling pointer )。當資源已經被釋放但指標卻還留著，這樣的指標指向的地方很可能就已經被別人所有了。在 Rust 中編譯器會保證引用絕不會是迷途引用。\nfn main() { let reference_to_nothing = dangle(); } fn dangle() -\u0026gt; \u0026amp;String { // 回傳 String 的迷途引用 let s = String::from(\u0026#34;hello\u0026#34;); // s 是個新 String \u0026amp;s // 我們回傳 String s 的引用 } // s 在此會離開作用域並釋放，它的記憶體就不見了。 // 危險！ s 是在 dangle 裡面產生的，當 dangle 結束 s 會被釋放。如果嘗試回傳 s，這個引用會指向一個無效的 String，所以 Rust 不會讓它發生。\n讓他回傳的值不是引用就可以了，這邊直接回傳 String就好：\nfn main() { let string = no_dangle(); } fn no_dangle() -\u0026gt; String { let s = String::from(\u0026#34;hello\u0026#34;); s } 切片 (Slice) 切片 (Slice) 可以引用一串集合的元素列，並非引用整個集合。切片也是一種引用，所以它沒有所有權。\n寫一個函式接收一串用空格分開單字的字串，如：Hello world、Good job，並回傳第一個找到的單字；如果沒有找到任何空格，就代表整個字串就是一個單字，並回傳整個字串。\nfn first_word(s: \u0026amp;String) -\u0026gt; usize { let bytes = s.as_bytes(); for (i, \u0026amp;item) in bytes.iter().enumerate() { if item == b\u0026#39; \u0026#39; { return i; } } s.len() } fn main() { let mut s = String::from(\u0026#34;hello world\u0026#34;); let word = first_word(\u0026amp;s); // word 取得數值 5 s.clear(); // 這會清空 String，這就等於 \u0026#34;\u0026#34; // word 仍然是數值 5 ，但是我們已經沒有相等意義的字串了 // 擁有 5 的變數 word 現在完全沒意義！ } let bytes = s.as_bytes();：將 String 轉換成一個位元組陣列 for (i, \u0026amp;item) in bytes.iter().enumerate()：使用 iter 方法對位元建立一個疊代器 (iterator) iter()：是一個回傳集合中的每個元素方法 enumerate()：回傳的元組中第一個是索引(i)，第二個是元素的引用(\u0026amp;item) if item == b' ' {return i} ：找到空格後回傳該位置，如果沒有就回傳整個字串長度 程式雖然可以成功編譯，可以看到 s 的內容與 word 是沒有直接關係的，所以當 s 改變後，直接使用 word 去獲得 s 的單字，就會造成錯誤，這也導致需要留意 word 是不是與 s 脫鉤，而這個麻煩可以使用 Rust 的 字串切片(tring slice)。\n字串切片 fn main() { let s = String::from(\u0026#34;hello world\u0026#34;); let hello = \u0026amp;s[0..5]; let world = \u0026amp;s[6..11]; } 基本上就是 Python 的 slice，只是用引用的方式\n與其引用整個 String，透過 [0..5] 來引用了一部分的 String。\n更改上方回傳字串的程式：\nfn first_word(s: \u0026amp;str) -\u0026gt; \u0026amp;str { let bytes = s.as_bytes(); for (i, \u0026amp;item) in bytes.iter().enumerate() { if item == b\u0026#39; \u0026#39; { return \u0026amp;s[0..i]; } } \u0026amp;s[..] } 可以將 fn first_word(s: \u0026amp;String) -\u0026gt; \u0026amp;String 寫成 fn first_word(s: \u0026amp;str) -\u0026gt; \u0026amp;str\n現在編譯器會確保 String 的引用是有效的，所以當使用以下程式碼進行編譯，就會直接跳出錯誤：\nfn main() { let mut s = String::from(\u0026#34;hello world\u0026#34;); let word = first_word(\u0026amp;s); // word 取得數值 5 s.clear(); // 錯誤 println!(\u0026#34;第一個單字為：{}\u0026#34;, word); } $ cargo run Compiling ownership v0.1.0 (file:///projects/ownership) error[E0502]: cannot borrow `s` as mutable because it is also borrowed as immutable --\u0026gt; src/main.rs:18:5 | 16 | let word = first_word(\u0026amp;s); | -- immutable borrow occurs here 17 | 18 | s.clear(); // 錯誤！ | ^^^^^^^^^ mutable borrow occurs here 19 | 20 | println!(\u0026#34;第一個單字為：{}\u0026#34;, word); | ---- immutable borrow later used here For more information about this error, try `rustc --explain E0502`. error: could not compile `ownership` due to previous error 出現錯誤是因為借用的規則：當呼叫 clear 會清除 String，這表示它必須是可變引用。在 clear 後呼叫 println! ，這時就會用到 word 的引用。Rust 不允許同時存在 clear 的可變引用與 word 的不可變引用，所以會編譯失敗。這就能讓這些錯誤在編譯期間就被發現，進而修改。\n結論 在高中時期有使用 Unity 製作過遊戲，當時所使用的就是 C# 程式語言，對於 GC 這個機制是不陌生的，而到了大學轉為寫網頁時，JavaScript 也有 GC 的機制來回收記憶體。第一次接觸 Rust 管理記憶體的方法，所有權的規則看似限制很多其實用起來很直覺，他可以預防很多問題，例如: 指標是空的、迷途指標等等。\n引用 理解所有權 ","permalink":"https://et860525.github.io/posts/rust-ownership/","summary":"\u003cp\u003e在一開始撰寫文章時，本來想以寫比較久的 TypeScript 來做部落格的開頭文章，但在過年前接觸到 Rust 這個程式語言，就順勢把最近學到的東西放上來。等到把在 TypeScript 遇到的問題整理一下再寫成一個系列放上來。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e所有權 ( ownership )\u003c/strong\u003e 是 Rust 用來 \u003cstrong\u003e管理程式記憶體的一系列規則\u003c/strong\u003e，讓 Rust 不需要\u003ca href=\"https://zh.wikipedia.org/zh-tw/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6_(%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A7%91%E5%AD%B8)\"\u003e垃圾回收 ( Garbage collection )\u003c/a\u003e 就可以保障記憶體的安全。\u003c/p\u003e","title":"Rust: 所有權( Ownership )"},{"content":"在初期建立部落格時，本來是想租一台虛擬主機，再把寫好的網頁丟上去，不過最後還是選擇使用 GitHub Pages。\nJekyll 是 Github 建議的靜態網站產生器，不過在查詢資料時發現由 Go 所建構的 Hugo，點進去網頁上面就寫著自己是「世界上最快的網站架設框架」，那不試試看怎麼行。\n安裝 Hugo Hugo 有兩種版本，標準版 (standard) 與擴充版 (extended)，官方推薦使用 擴充版。\n下載的方式是根據自己的作業系統來選擇，而我使用的是 Linux，其他的作業系統可以參考 Hugo Installation。\n對於 Linux 系統，最簡單的方式就是直接使用 Package managers 下載：\nsudo apt install hugo 但是用這個方式下載的通常都不是最新版本，所以 Hugo 還提供 Prebuilt binaries 的方式，下載前要先確定版本 (使用當下是 v0.109.0)：\ncd /tmp \u0026amp;\u0026amp; mkdir hugo-binary \u0026amp;\u0026amp; cd hugo-binary wget https://github.com/gohugoio/hugo/releases/download/v0.109.0/hugo_extended_0.109.0_linux-amd64.tar.gz tar -xvf hugo_extended_0.109.0_linux-amd64.tar.gz cd ../ \u0026amp;\u0026amp; rm -rf hugo-binary/ hugo version 最後如果有出現版本號就是成功安裝了。\n初始化網站 使用以下得指令來建立專案的目錄：\nhugo new site my_blog 進到資料夾裡找到 config.toml，這個是 Hugo 的設定檔。\n如果你不喜歡使用 config.toml，Hugo 有提供 config.yaml 或 config.json，在建立專案時使用 hugo new my_project -f \u0026lt;yaml or json\u0026gt;\n選擇主題 可以到 Hugo Themes 來選擇你想要的主題，我這裡使用 hugo-PaperMod：\ncd my_blog git init # 初始化 Git git submodule add --depth=1 https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod git submodule update --init --recursive # needed when you reclone your repo (submodules may not get cloned automatically) 接著將主題名稱加入 config.toml：\ntheme = \u0026#34;PaperMod\u0026#34; 通常下載的主題裡面都會有 exampleSite 或是將它獨立出來，都能在該主題的 Github 找到。exampleSite 裡都會有已經設定好的 config.toml 可以直接套用，也可以根據自己的需求來設定。\n可以將 exampleSite 的 content 裡的檔案都放進專案的 content 裡，這就是預設的文章，可以在運行網站時先預覽顯示的狀態\n運行網站 hugo server 如果沒有任何錯誤，就可以到 http://localhost:1313 來觀看網站。\n這個網站只運行在你的電腦上，要放到 GitHub Pages 上才能讓其他人看到\n部屬到 GitHub Pages 首先，先在 Github 建立新的專案，名字為 \u0026lt;your-account\u0026gt;.github.io。\n根據官方文件 Host on GitHub，使用 GitHub Action 來部屬網站，在根目錄下新增檔案 .github/workflows/gh-pages.yml，該檔案的程式碼為：\nname: github pages on: push: branches: - main # Set a branch that will trigger a deployment pull_request: jobs: deploy: runs-on: ubuntu-22.04 steps: - uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;latest\u0026#39; # extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 if: github.ref == \u0026#39;refs/heads/main\u0026#39; with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./public 完成後再把專案推上去：\ngit status git add . git commit -m \u0026#34;Init my hugo blog\u0026#34; git branch -M main git remote add origin git@github.com:\u0026lt;your-account\u0026gt;/\u0026lt;your-account\u0026gt;.github.io.git git push -u origin master 到該 repo 的 Actions 就會看到以下畫面：\n如果有出現錯誤，請到 Repo -\u0026gt; Settings -\u0026gt; Actions -\u0026gt; General 確認\nActions permissions 設定為 Allow all actions and reusable workflows Workflow permissions 設定為 Read and write permissions Actions 完成編譯後，設定 Github Pages 要使用的 branch：\n最後再到 https://\u0026lt;your-account\u0026gt;.github.io/ 就能看到設定的頁面了。\n","permalink":"https://et860525.github.io/posts/hugo-with-github-pages/","summary":"\u003cp\u003e在初期建立部落格時，本來是想租一台虛擬主機，再把寫好的網頁丟上去，不過最後還是選擇使用 \u003ca href=\"https://pages.github.com/\"\u003eGitHub Pages\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003eJekyll 是 Github 建議的靜態網站產生器，不過在查詢資料時發現由 Go 所建構的 \u003ca href=\"https://gohugo.io/\"\u003eHugo\u003c/a\u003e，點進去網頁上面就寫著自己是「世界上最快的網站架設框架」，那不試試看怎麼行。\u003c/p\u003e","title":"將 Hugo 產生的靜態網站部屬在 GitHub Pages"}]